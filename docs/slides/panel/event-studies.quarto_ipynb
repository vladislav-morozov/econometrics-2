{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Event Studies\"\n",
        "subtitle: \"Simple Panel Data Approaches with Binary Treatment\"\n",
        "author: Vladislav Morozov  \n",
        "format:\n",
        "  revealjs:\n",
        "    include-in-header: \n",
        "      text: |\n",
        "        <meta name=\"description\" content=\"Panel data event studies: causal analysis, regression interpretation, and applications to Silicon Valley Bank collapse (lecture notes slides).\"/>\n",
        "    width: 1150\n",
        "    slide-number: true\n",
        "    sc-sb-title: true\n",
        "    incremental: true   \n",
        "    logo: ../../themes/favicon.ico\n",
        "    footer: \"Panel Data: Event Studies\"\n",
        "    footer-logo-link: \"https://vladislav-morozov.github.io/econometrics-2/\"\n",
        "    theme: ../../themes/slides_theme.scss\n",
        "    toc: TRUE\n",
        "    toc-depth: 2\n",
        "    toc-title: Contents\n",
        "    transition: convex\n",
        "    transition-speed: fast\n",
        "slide-level: 4\n",
        "title-slide-attributes:\n",
        "    data-background-color: \"#045D5D\"\n",
        "    data-footer: \" \"\n",
        "filters:\n",
        "  - reveal-header  \n",
        "include-in-header: ../../themes/mathjax.html \n",
        "highlight-style: tango\n",
        "open-graph:\n",
        "    description: \"Panel data event studies: causal analysis, regression interpretation, and applications to Silicon Valley Bank collapse (lecture notes slides).\"\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Introduction {background=\"#00100F\"}\n",
        "  \n",
        "### Lecture Info {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        "\n",
        "#### Learning Outcomes\n",
        "\n",
        "This lecture is about a simple kind of causal studies with panel data — comparing outcomes from before and after treatment\n",
        "\n",
        "<br>\n",
        "\n",
        "By the end, you should be able to\n",
        "\n",
        "- Write down event study estimators with two or more periods of data\n",
        "- Define an appropriate causal framework\n",
        "- Prove consistency of event study estimators under an assumption of no trends \n",
        "  \n",
        "#### References\n",
        " \n",
        "\n",
        "::: {.nonincremental}\n",
        "\n",
        "\n",
        "- Chapter 17 in @Huntington-Klein2025EffectIntroductionResearch: <https://www.theeffectbook.net/ch-EventStudies.html>\n",
        "- @MacKinlay1997EventStudiesEconomics, @Freyaldenhoven2021VisualizationIdentificationEstimation, @Miller2023IntroductoryGuideEvent\n",
        "- NBER 2023 Methods Lectures on Linear Panel Event Studies: <https://www.nber.org/conferences/si-2023-methods-lectures-linear-panel-event-studies>\n",
        "  \n",
        ":::  \n"
      ],
      "id": "47fc5db4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import statsmodels.api as sm\n",
        "import yfinance as yf\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
        "plt.rcParams[\"font.sans-serif\"] = [\"Arial\"]\n",
        "\n",
        "BG_COLOR = \"whitesmoke\""
      ],
      "id": "4b0aed68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Empirical Motivation {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        "#### Event {#sec-event-study-svb-example}\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "*March 10, 2023*: third-largest bank failure in the US: the Silicon Valley Bank (SVB) collapses\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "- Bank collapses are painful for depositors and creditors\n",
        "- Collapses also raise fears of broader financial contagion — danger to other financial institutions\n",
        "\n",
        "#### Empirical Question {.scrollable}\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "How did the collapse of the SVB affect stock prices of other US financial institutions in the next 10 days? \n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "- Causal question: comparing prices after collapse with prices without collapse\n",
        "- How to do this comparison? What assumptions do we need?\n"
      ],
      "id": "4d4c2495"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Expand for list of institutions of interest\"\n",
        "\n",
        "tickers = [\n",
        "    \"ALLY\",  # Ally Financial Inc.\n",
        "    \"AMTB\",  # Amerant Bancorp Inc.\n",
        "    \"ABCB\",  # Ameris Bancorp\n",
        "    \"ASB\",   # Associated Banc-Corp\n",
        "    \"AUB\",   # Atlantic Union Bankshares Corporation\n",
        "    \"AX\",    # Axos Financial Inc.\n",
        "    \"BANC\",  # Banc of California Inc.\n",
        "    \"BK\",    # Bank of New York Mellon Corporation\n",
        "    \"BAC\",   # Bank of America Corporation\n",
        "    \"BOH\",   # Bank of Hawaii Corporation\n",
        "    \"BKU\",   # BankUnited Inc.\n",
        "    \"BHB\",   # Bar Harbor Bankshares Inc.\n",
        "    \"BHLB\",  # Berkshire Hills Bancorp Inc.\n",
        "    \"BRBS\",  # Blue Ridge Bankshares Inc.\n",
        "    \"CADE\",  # Cadence Bank\n",
        "    \"COF\",   # Capital One Financial Corporation\n",
        "    \"C\",     # Citigroup Inc.\n",
        "    \"CFG\",   # Citizens Financial Group Inc.\n",
        "    \"CMA\",   # Comerica Incorporated\n",
        "    \"CFR\",   # Cullen/Frost Bankers Inc. \n",
        "    \"FNB\",   # F.N.B. Corporation\n",
        "    \"FBK\",   # FB Financial Corporation\n",
        "    \"FITB\",  # Fifth Third Bancorp\n",
        "    \"HBAN\",  # Huntington Bancshares Incorporated\n",
        "    \"KEY\",   # KeyCorp\n",
        "    \"MTB\",   # M&T Bank Corporation\n",
        "    \"PNC\",   # PNC Financial Services Group Inc.\n",
        "    \"RF\",    # Regions Financial Corporation\n",
        "    \"STT\",   # State Street Corporation\n",
        "    \"SYF\",   # Synchrony Financial\n",
        "    \"USB\",   # U.S. Bancorp\n",
        "    \"WFC\",   # Wells Fargo & Company\n",
        "    \"SCHW\",  # Charles Schwab Corporation\n",
        "    \"AXP\",   # American Express Company\n",
        "    \"DFS\",   # Discover Financial Services\n",
        "    \"NTB\",   # Bank of N.T. Butterfield & Son Limited\n",
        "    \"EWBC\",  # East West Bancorp Inc.\n",
        "    \"WAL\",   # Western Alliance Bancorporation\n",
        "    \"SSB\",   # SouthState Corporation\n",
        "    \"WBS\",   # Webster Financial Corporation\n",
        "    \"FHN\",   # First Horizon Corporation\n",
        "    \"PNFP\",  # Pinnacle Financial Partners Inc.\n",
        "    \"HOMB\",  # Home BancShares Inc.\n",
        "    \"HTH\",   # Hilltop Holdings Inc.\n",
        "    \"GBCI\",  # Glacier Bancorp Inc.\n",
        "    \"BOKF\",  # BOK Financial Corporation\n",
        "    \"ZION\",  # Zions Bancorporation\n",
        "    \"TCBI\",  # Texas Capital Bancshares Inc.\n",
        "    \"CIVB\",  # Civista Bancshares Inc.\n",
        "    \"CFFI\",  # C&F Financial Corporation\n",
        "    \"BANF\",  # BancFirst Corporation\n",
        "    \"FULT\",  # Fulton Financial Corporation\n",
        "    \"ONB\",   # Old National Bancorp\n",
        "    \"PB\",    # Prosperity Bancshares Inc.\n",
        "    \"UBSI\",  # United Bankshares Inc.\n",
        "    \"VLY\",   # Valley National Bancorp\n",
        "    \"TRMK\",  # Trustmark Corporation \n",
        "    \"CASH\",  # Meta Financial Group Inc.\n",
        "    \"CUBI\",  # Customers Bancorp Inc.\n",
        "    \"CFFN\",  # Capitol Federal Financial Inc.\n",
        "    \"FFIN\",  # First Financial Bankshares Inc. \n",
        "    \"SFBS\",  # ServisFirst Bancshares Inc.\n",
        "    \"TBBK\",  # The Bancorp Inc. \n",
        "    \"WSBC\",  # WesBanco Inc.\n",
        "    \"WTFC\",  # Wintrust Financial Corporation\n",
        "]"
      ],
      "id": "763c35da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "\n",
        ":::\n",
        "\n",
        "## Two Periods {background=\"#00100F\"}\n",
        " \n",
        " \n",
        "### Estimator {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        "\n",
        "#### Simple Event Study Setting\n",
        "\n",
        "Begin with the simplest possible panel setting with binary treatment: \n",
        " \n",
        "- Two periods with $N$ units:\n",
        "  - No treatment in period 1\n",
        "  - All units treated in period 2\n",
        "- Data: outcomes $(Y_{i1}, Y_{i2})$.\n",
        "\n",
        ". . .\n",
        "\n",
        "Object of interest: \"average effect of treatment\"\n",
        "\n",
        "#### Simple Estimator — Average Change\n",
        "\n",
        "Simplest approach: compute average change in $Y_{it}$ across periods\n",
        "  $$\n",
        "  \\widehat{AE}_{ES} = \\dfrac{1}{N}\\sum_{i=1}^N (Y_{i2}- Y_{i1}).\n",
        "  $$ {#eq-causal-event-studies-naive-panel-contrast}\n",
        "  \n",
        "\n",
        "Estimator ([-@eq-causal-event-studies-naive-panel-contrast]) — simplest example of *event study* estimators [see  @Freyaldenhoven2021VisualizationIdentificationEstimation;@Miller2023IntroductoryGuideEvent]\n",
        "\n",
        "#### Example Framework {#sec-event-study-example}\n",
        "\n",
        "Possible empirical framework\n",
        "\n",
        "- Units $i$: firms that make phones\n",
        "- Outcome $Y_{it}$: their stock price\n",
        "- Periods:\n",
        "  1. One week before Apple announces the iPhone\n",
        "  2. One week after the announcement\n",
        "\n",
        ". . .\n",
        "\n",
        "Effect of interest: change in stock prices due to the announcement of iPhone\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### What Does ([-@eq-causal-event-studies-naive-panel-contrast]) Do?\n",
        "\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "::: {#prp-event-study-limit}\n",
        "\n",
        "## Asymptotics for $\\widehat{AE}_{ES}$\n",
        "\n",
        "Let \n",
        "\n",
        "::: {.nonincremental}\n",
        "- *(Cross-sectional random sampling)*: $(Y_{i1}, Y_{i2})$ be independent and identically distributed (IID)\n",
        "- *Finite first moments*: $\\E[\\abs{Y_{it}}]<\\infty$\n",
        ":::\n",
        " \n",
        "Then\n",
        "$$\n",
        "\\widehat{AE}_{ES} \\xrightarrow{p} \\E[Y_{i2} - Y_{i1}].\n",
        "$$ \n",
        ":::\n",
        "\n",
        "</div>\n",
        "\n",
        "### Causal Analysis {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        "\n",
        "#### Causal Framework\n",
        "\n",
        "\n",
        "Is $\\E[Y_{i2} - Y_{i1}]$ interesting (=causal)?\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-important appearance=\"minimal\"}\n",
        "\n",
        "Need a causal framework to talk about causal effects!\n",
        "\n",
        ":::\n",
        "\n",
        ". . .\n",
        "\n",
        "Again work in the familiar potential outcomes framework: \n",
        "\n",
        "- $Y_{it}^0$ — outcome for $i$ in period $t$ if *not treated*\n",
        "- $Y_{i1}^1$ — outcome for $i$ in period $t$ if *treated*\n",
        "- Treatment effect for $i$ in $t$: $Y_{it}^1- Y_{it}^0$\n",
        "\n",
        ". . .\n",
        "\n",
        "For short, use $Y_{it}^d$ where $d=0, 1$\n",
        "\n",
        "\n",
        "\n",
        "#### Limit of ES Estimator and Causality\n",
        "\n",
        "Potential and *realized* outcomes are connected as\n",
        "$$\n",
        "Y_{i2} = Y_{i2}^1, \\quad Y_{i1} = Y_{i1}^0.\n",
        "$$\n",
        "\n",
        "\n",
        ". . .\n",
        "\n",
        "It follows that\n",
        "$$\n",
        "\\widehat{AE}_{ES} \\xrightarrow{p} \\E[Y_{i2}^1- Y_{i1}^0].\n",
        "$$\n",
        "\n",
        "::: {.callout-important appearance=\"minimal\"}\n",
        " \n",
        "$\\E[Y_{i2}^1- Y_{i1}^0]$ is not necessarily a treatment effect — mixes effect of treatment and effects of time!\n",
        "::: \n",
        "\n",
        "#### Example\n",
        "\n",
        "[[Context]{.button}](#sec-event-study-example) Again consider the iPhone example. Then \n",
        "\n",
        "- $Y_{i2}^1 - Y_{i2}^0$ — treatment effect, change in price *because* of the iPhone announcement\n",
        "- $Y_{i2}^0 - Y_{i1}^0$ — change in a world *without* iPhone\n",
        "  \n",
        ". . . \n",
        "\n",
        "<br>\n",
        "\n",
        "Realized difference = combination of both changes\n",
        "$$\n",
        "Y_{i2} - Y_{i1} = Y_{i2}^1- Y_{i1}^0 = [Y_{i2}^1- Y_{i2}^0] + [Y_{i2}^0 - Y_{i1}^0]\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "#### Solution: Restrict Changes over Time\n",
        "\n",
        "Simple solution: rule out changes over time\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "**Assumption**: no variation in potential outcomes\n",
        "$$\n",
        "Y_{i2}^d= Y_{i1}^d, \\quad d=0, 1\n",
        "$$ \n",
        " \n",
        "\n",
        "</div>\n",
        "\n",
        "Then $\\widehat{AE}_{ES}$ is estimating a *causal* parameter — average effects:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\widehat{AE}_{ES} & \\xrightarrow{p} \\E[Y_{i1}^1- Y_{i1}^0]  =  \\E[Y_{i2}^1- Y_{i2}^0]\n",
        "\\end{aligned}\n",
        "$$ \n",
        "\n",
        "#### Relaxing Time Invariance: No Trends\n",
        "\n",
        "Time invariance very strict. Why use it if we only work with averages?\n",
        "\n",
        ". . .\n",
        "\n",
        "Weaker assumption:\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "**Assumption** (*no trends*):  \n",
        "$$\n",
        "\\E[Y_{i2}^d] = \\E[Y_{i1}^d], \\quad d=0, 1\n",
        "$$\n",
        " \n",
        "\n",
        "</div>\n",
        "Allows random variation in potential outcomes between times\n",
        "\n",
        "#### Summary so Far\n",
        "\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "::: {#prp-event-study-no-trends}\n",
        "\n",
        "## Causal asymptotics for $\\widehat{AE}_{ES}$\n",
        "\n",
        "Let \n",
        "\n",
        "::: {.nonincremental}\n",
        "- Assumptions of @prp-event-study-limit hold\n",
        "- Assumption of no trends holds\n",
        ":::\n",
        " \n",
        "Then $\\widehat{AE}_{ES}$ consistent for causal parameters:\n",
        "$$\n",
        "\\widehat{AE}_{ES} \\xrightarrow{p} \\E[Y_{i1}^1- Y_{i1}^0]  =  \\E[Y_{i2}^1- Y_{i2}^0]\n",
        "$$ \n",
        ":::\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "### Regression Interpretation {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        " \n",
        "\n",
        "#### Regression Setting\n",
        "\n",
        "Can also connect $\\widehat{AE}_{ES}$ and OLS \n",
        "\n",
        ". . . \n",
        " \n",
        "Consider regressing $Y_{it}$ on $(1, D_{it})$ where\n",
        "$$\n",
        "\\begin{aligned}\n",
        "% Y_{it} & = \\beta_0 + \\beta_1 D_{it} + U_{it}, \\\\\n",
        "D_{it} & = \\begin{cases}\n",
        "1, & t= 1 \\\\\n",
        "0, & t =0\n",
        "\\end{cases}\n",
        "\\end{aligned}\n",
        "$${#eq-event-study-simple-regression}\n",
        "and where we simply treat $(Y_{i1}, D_{i1})$ and $(Y_{i2}, D_{i2})$ as separate observations\n",
        "\n",
        "\n",
        "\n",
        "#### Event Studies and OLS\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "::: {#prp-event-study-no-trends}\n",
        "\n",
        "## $\\widehat{AE}_{ES}$ is OLS\n",
        "\n",
        "For $\\beta_1$ of regression  ([-@eq-event-study-simple-regression])\n",
        "$$\n",
        "\\widehat{AE}_{ES} = \\hat{\\beta}_1,\n",
        "$$ \n",
        "where $\\hat{\\beta}_1$ is the estimator of the coefficient on $D_{it}$\n",
        ":::\n",
        "\n",
        "\n",
        "</div> \n",
        "\n",
        "Can use all results developed for OLS for $\\widehat{AE}_{ES}$\n",
        " \n",
        "   \n",
        "\n",
        "#### Event Study and Regression I\n",
        "\n",
        "A way to think about regression in causal settings:\n",
        "\n",
        "- Write down the regression in terms of parameters of interest: e.g. let\n",
        "$$ \n",
        "\\begin{aligned}\n",
        "Y_{it} & = \\beta_0 + \\beta_1 D_{it} + U_{it},\n",
        "\\\\\n",
        "\\beta_0 & = \\E[Y_{i1}^0], \\quad\n",
        "\\beta_1  =  \\E[Y_{i2}^1- Y_{i2}^0] \n",
        "\\end{aligned}\n",
        "$$\n",
        "- Connect regression to potential outcomes: *what is $U_{it}$ in terms of potential outcomes? (exercise)* \n",
        " \n",
        "#### Event Study and Regression II\n",
        "\n",
        "Let $\\bX_{it} = (1, D_{it})'$. Then\n",
        "\n",
        "- By properties of OLS know that OLS is consistent for $\\bbeta = (\\beta_0, \\beta_1)$ if\n",
        "  -  $\\E[\\bX_{it}U_{it}] =0$  \n",
        "  -  $\\E[\\bX_{it}\\bX_{it}']$ invertible\n",
        "\n",
        "- So just need to check if this $U_{it}$ satisfies $\\E[\\bX_{it}U_{it}] =0$ \n",
        "- If yes, OLS can estimate average effects of interest\n",
        " \n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-important appearance=\"minimal\"}\n",
        "\n",
        "Remember: the OLS \"model\" and the underlying causal model are separate things! Here the causal model is \"nonparametric\"\n",
        ":::\n",
        "\n",
        "\n",
        "::: footer\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Multiple Periods {background=\"#00100F\"}\n",
        "\n",
        " \n",
        "### Estimation and Causal Framework {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        " \n",
        "#### Multiple Period Framework\n",
        "\n",
        "- Often have more than 2 periods of data\n",
        "- Want to use that data\n",
        "\n",
        ". . . \n",
        "\n",
        "New framework:\n",
        "\n",
        "- $T$ periods in total\n",
        "- Treatment starts in period $t_0$\n",
        "- We see $Y_{it}^0$ for $t<t_0$ and $Y_{it}^1$ for $t\\geq t_0$\n",
        "\n",
        "#### Expanded Regression\n",
        "\n",
        "New variables for treatment: \n",
        "$$\\small\n",
        "D_{it, \\tau} = \\begin{cases}\n",
        "1, & t= \\tau, \\\\\n",
        "0, & t\\neq \\tau\n",
        "\\end{cases}\n",
        "$$\n",
        " \n",
        ". . . \n",
        "\n",
        "Can try similar regression:\n",
        "$$\\small\n",
        "Y_{it} = \\beta_0 +  \\sum_{\\tau = t_0}^{T} \\beta_\\tau D_{it, \\tau} + u_{it}\n",
        "$${#eq-event-studies-long-regression}\n",
        "Let $\\hat{\\bbeta}=(\\hat{\\beta}_0, \\hat{\\beta}_{t_0}, \\dots, \\hat{\\beta}_{T}$) be the OLS estimator\n",
        "\n",
        "#### OLS Estimator Expression \n",
        "\n",
        "Fairly easy to show that\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\hat{\\beta}_{\\tau} & = \\dfrac{1}{N} \\sum_{i=1}^N Y_{i\\tau} - \\dfrac{1}{N(t_0-1)} \\sum_{i=1}^N\\left[ Y_{i1} + \\dots + Y_{it_0-1} \\right] \\\\\n",
        "& \\xrightarrow{p} \\E\\left[Y_{i\\tau}^1  - \\dfrac{1}{t_0-1}(Y_{i1}^0+ \\dots + Y_{it_0-1}^0) \\right]\n",
        "\\end{aligned}\n",
        "$$\n",
        "More general version of the simple estimator of before\n",
        "\n",
        "#### Dynamic Treatment Effects?\n",
        "\n",
        "If $\\beta_{\\tau}$ — average effect in period $\\tau$, then model ([-@eq-event-studies-long-regression]) seems to allow for *dynamic* effects\n",
        "\n",
        "\n",
        ". . . \n",
        " \n",
        "<br>\n",
        "\n",
        "Dynamic effects <span class=\"highlight\">realistic</span>: effect of treatment may change over time. Example: impact of job training on earnings:\n",
        "\n",
        "- Disappearing: you forget the training over time\n",
        "- Increasing: job training lets you jump to a higher position and gain experience quicker for the rest of your life\n",
        "\n",
        " \n",
        "#### No Trends Rule Out Dynamics\n",
        "\n",
        "Suppose that the *no trends* assumption holds\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& \\E\\left[Y_{i\\tau}^1  - \\dfrac{1}{t_0-1}(Y_{i1}^0+ \\dots + Y_{it_0-1}^0) \\right]  = \\E[Y_{it}^1 - Y_{it}^0]\n",
        "\\end{aligned}\n",
        "$$\n",
        "The right hand side does <span class=\"highlight\">not</span> depend on $t$\n",
        "\n",
        ". . . \n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "No dynamic treatment effects under no trends!\n",
        "\n",
        "</div> \n",
        "<span class=\"highlight\">Bad</span>, since we want to allow for dynamics\n",
        "\n",
        "\n",
        "#### Relaxing No Trends Assumption\n",
        "\n",
        "Can relax no trends to only affect *one* of the potential outcomes — makes more sense to restrict the untreated outcome (why?)\n",
        "\n",
        "<br>\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "**Assumption** (*no trends in the baseline*): $\\E[Y_{it}^0]$ does not depend on $t$\n",
        " \n",
        "\n",
        "</div>\n",
        " \n",
        "#### Recovering Dynamic Average Treatment Effects\n",
        "\n",
        "\n",
        "Under assumption of no trends in the baseline:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "& \\E\\left[Y_{i\\tau}^1  - \\dfrac{1}{t_01}(Y_{i1}^0+ \\dots + Y_{it_0-1}^0) \\right]  = \\E[Y_{i \\tau}^1 - Y_{i\\tau}^0]\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "<br> \n",
        "\n",
        "Right hand side is average effect in period $\\tau$\n",
        "\n",
        " \n",
        "\n",
        "### Asymptotic Properties {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        "\n",
        "#### Consistency in the Multivariate Case\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "::: {#prp-event-study-no-trends-multivariate}\n",
        "\n",
        "Let \n",
        "\n",
        "::: {.nonincremental}\n",
        "- Assumptions of @prp-event-study-limit hold\n",
        "- No trends in the baseline assumption hold\n",
        ":::\n",
        " \n",
        "Then $\\hat{\\beta}_{\\tau}$ consistently estimates the average treatment effect in period $\\tau$ given by $\\E[Y_{i \\tau}^1 - Y_{i\\tau}^0]$. \n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Unbiasedness of OLS\n",
        "\n",
        "Moreover, under no trends in the baseline\n",
        "$$\n",
        "\\E[\\hat{\\beta}_{\\tau}] = \\E[Y_{i \\tau}^1 - Y_{i\\tau}^0]\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        "\n",
        "\n",
        "In other words, the OLS estimator is unbiased\n",
        "\n",
        "#### Asymptotic Distribution\n",
        "\n",
        " \n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "::: {#prp-event-study-no-trends-multivariate-distribution}\n",
        "\n",
        "Let \n",
        "\n",
        "::: {.nonincremental} \n",
        "- No trends in the baseline assumption hold \n",
        "- $(Y_{i1}, Y_{i2}, \\dots, Y_{iT})$ be IID (over $i$)\n",
        "- *Finite second moments*: $\\E[Y_{it}^2]<\\infty$\n",
        ":::\n",
        " \n",
        "Then there exists some variance $V$ such that\n",
        "$$\n",
        "\\sqrt{N}\\left( \\hat{\\beta}_{\\tau} - \\E[Y_{i \\tau}^1 - Y_{i\\tau}^0] \\right) \\Rightarrow N(0, V)\n",
        "$$\n",
        ":::\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "<!-- #### Asymptotic Variance I\n",
        "\n",
        "Need variance $V$ to construct confidence intervals for $\\E[Y_{i \\tau}^1 - Y_{i\\tau}^0]$. How to find $V$? Remember the CLT:\n",
        "\n",
        ". . .\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "If $X_1, X_2, \\dots$ are IID random variables with $\\E[X_i]=\\mu$ and $\\E[X^2]<\\infty$, then\n",
        "$$\n",
        "\\sqrt{N}\\left( \\dfrac{1}{N}\\sum_{i=1}^N X_i - \\mu  \\right)\\Rightarrow N\\left(0, \\var(X_i) \\right)\n",
        "$$\n",
        "Asymptotic variance = variance of $X_i$\n",
        "</div>\n",
        "  -->\n",
        "\n",
        "####  Asymptotic Variance \n",
        "\n",
        "Need variance $V$ to construct confidence intervals for $\\E[Y_{i \\tau}^1 - Y_{i\\tau}^0]$. \n",
        "\n",
        ". . . \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\hat{\\beta}_{\\tau} & = \\dfrac{1}{N} \\sum_{i=1}^N Z_i\\\\\n",
        "Z_i & =  Y_{i\\tau} - \\dfrac{1}{(t_0-1)}\\left[ Y_{i1} + \\dots + Y_{it_0-1} \\right]\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        ". . .\n",
        " \n",
        "From central limit theorem:\n",
        "$$\n",
        "V = \\var(Z_i)\n",
        "$$\n",
        "\n",
        "#### Estimator for Asymptotic Variance\n",
        "\n",
        "Can estimate $V$ with \n",
        "$$\n",
        "\\hat{V} = \\widehat{\\var}(Z_i) = \\dfrac{1}{N}\\left(Z_i - \\dfrac{1}{N}\\sum_{j=1}^N Z_j \\right)^2\n",
        "$$\n",
        "\n",
        ". . . \n",
        "\n",
        "Estimated standard error of $\\hat{\\beta}_{\\tau}$:\n",
        "$$\n",
        "\\widehat{se}(\\hat{\\beta}_{\\tau}) = \\sqrt{ \\dfrac{\\hat{V}}{N} }\n",
        "$$\n",
        "\n",
        "#### Inference on Average Effects I\n",
        "\n",
        "Can now construct confidence intervals and hypothesis tests about $\\E[Y_{i \\tau}^1 - Y_{i\\tau}^0]$. E.g. an asymptotic 95% confidece interval:\n",
        "$$\n",
        "\\widehat{CI}_{95\\%} = \\left[\\hat{\\beta}^{OLS}_{\\tau} - z_{1-\\alpha/2}\\widehat{se}(\\hat{\\beta}_{\\tau}), \\hat{\\beta}^{OLS}_{\\tau} + z_{1-\\alpha/2}\\widehat{se}(\\hat{\\beta}_{\\tau}) \\right]\n",
        "$$\n",
        "where the critical values $z_{1-\\alpha/2}$ come from the standard normal distribution\n",
        "$$\n",
        " z_{1-\\alpha/2}= \\Phi^{-1}\\left(1 - \\dfrac{\\alpha}{2} \\right)\n",
        "$$\n",
        "\n",
        "#### Inference on Average Effects II\n",
        "\n",
        "But what if we want to set the *joint* hypothesis\n",
        "$$\n",
        "H_0: \\beta_{\\tau} = 0, \\quad \\tau = t_0, \\dots, T\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "- This $H_0$ is a hypothesis above a *vector* of effects \n",
        "- To write down a Wald test we need the *joint* asymptotic distribution of $\\hat{\\bbeta}$\n",
        "\n",
        "\n",
        "#### Joint Asymptotic Distribution\n",
        "\n",
        "\n",
        "<div style=\"border: 2px solid #ccc; padding: 9px; border-radius: 15px; margin-bottom: 10px;\">\n",
        "\n",
        "::: {#prp-event-study-joint-limit-distribution}\n",
        "\n",
        "## Joint Asymptotics for Estimated Effects\n",
        "\n",
        "Let \n",
        "\n",
        "::: {.nonincremental} \n",
        "- Assumption of no trends in the baseline hold\n",
        "- $(Y_{i1}, Y_{i2}, \\dots, Y_{iT})$ be IID (over $i$) with finite second moments\n",
        ":::\n",
        " \n",
        "Then  \n",
        "$$ \\small\n",
        "\\sqrt{N}(\\hat{\\bbeta} -\\bbeta) \\Rightarrow N(0, \\avar(\\hat{\\bbeta}))\n",
        "$$ \n",
        ":::\n",
        "\n",
        "</div>\n",
        "\n",
        "#### Joint Inference on Average Effects: Wald Test\n",
        "\n",
        "Can use @prp-event-study-joint-limit-distribution to create a Wald test:\n",
        "\n",
        "- Write $H_0$ as $H_0: \\bR\\bbeta = \\bq$ for\n",
        "$$ \\small\n",
        "\\bR = \\begin{pmatrix}\n",
        "\\mathbf{0} & \\bI_{T-t_0+1}\n",
        "\\end{pmatrix}, \\quad \\bq = \\mathbf{0}\n",
        "$$\n",
        "\n",
        "- Write down Wald statistic:\n",
        "$$ \\small\n",
        "W = N(\\bR\\hat{\\bbeta}-\\bq)'(\\bR\\widehat{\\avar}(\\hat{\\bbeta})\\bR')^{-1}(\\bR\\hat{\\bbeta}-\\bq)\n",
        "$$\n",
        "\n",
        "- Compare to $(1-\\alpha)$th quantile of $\\chi^2_{T-t_0+1}$ distribution\n",
        "\n",
        "## Empirical Application {background=\"#00100F\"}\n",
        "\n",
        "\n",
        "### Formalizing the Application {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        "#### Back to Empirical Application\n",
        "\n",
        "Now let's answer our empirical question — impact of the SVB collapse on stock returns of US financial institutions [[Context]{.button}](#sec-event-study-svb-example)\n",
        "\n",
        "<br>\n",
        "\n",
        ". . . \n",
        "\n",
        "We need\n",
        "\n",
        "- Outcome variables (which returns?)\n",
        "- Time context $t$\n",
        "- How to define the treatment \n",
        "\n",
        "#### Some Finance Background: Abnormal Returns \n",
        "\n",
        "In finance, usually work with <span class=\"highlight\">abnormal returns $AR_{it}$</span> [@MacKinlay1997EventStudiesEconomics]\n",
        "\n",
        "<br>\n",
        "\n",
        "- Each stock $i$ assumed to have a \"normal\" or \"expected\" return $ER_{it}$ given market conditions on day $t$ — everything \"expected\" by the market\n",
        "- $AR_{it}$ — differences between actual return $R_{it}$ and $ER_{it}$:\n",
        "$$ \\small\n",
        "R_{it} = ER_{it} + AR_{it}\n",
        "$$\n",
        "\n",
        "#### Interest: Impact on Abnormal Returns\n",
        "\n",
        "Outcome of interest: $AR_{it}$\n",
        "\n",
        "<br>\n",
        "\n",
        ". . .\n",
        " \n",
        "\n",
        "|$d=0$ | $d=1$|\n",
        "|:---:|:----:|\n",
        "|Only idiosyncratic day-to-day shifts| Impact of SVB collapse + idiosyncratic movements|\n",
        "\n",
        ": Potential outcomes {.striped .hover .bordered}\n",
        "\n",
        "<br> \n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Assume that $\\E[AR_{it}^0] = 0$ and $AR_{it}^0$ uncorrelated with broader market characteristics\n",
        "\n",
        "</div>  \n",
        "\n",
        "::: footer\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "#### Computing Expected and Abnormal Returns\n",
        "\n",
        "Expected returns usually given by some model:\n",
        "\n",
        "- Simple mean model: let $R_{it}$ be return of asset $i$ on $t$. Expected return $ER_{it} = \\E[R_{it}]$\n",
        "- Factor models: \n",
        "$$\\small\n",
        "ER_{it} = f_i\\left( \\text{Some market characteristics on }t \\right)\n",
        "$$\n",
        "Example: $ER_{it} = \\bbeta_i'\\bx_{t}$ where $\\bx_{t}$ includes market return on $t$ (CAPM), or also small minus big, high minus low (Fama-French 3 factor)\n",
        "\n",
        "::: footer\n",
        "\n",
        "Check out @Fama2014TwoPillarsAsset Nobel Prize lecture for some background and history\n",
        "\n",
        ":::\n",
        "\n",
        "#### Estimating Model Parameters\n",
        "\n",
        "- Can compute $ER_{it}$ (and $AR_{it}$) if know model parameters\n",
        "- But how to compute parameters? \n",
        "\n",
        ". . . \n",
        "\n",
        "<br> \n",
        "\n",
        "Select estimation window with $D_{it}=0$. Then \n",
        "$$\n",
        "R_{it} = \\bbeta_i'\\bx_t + AR_{it}^0, \\quad \\E[AR_{it}^0\\bx_t] =0\n",
        "$$\n",
        "Can consistently estimate $\\bbeta_i$ by regressing $R_{it}$ on $\\bx_t$ (why — measurement error in dependent variable)\n",
        "\n",
        "#### Computing Abnormal Returns\n",
        "\n",
        "Work with estimated abnormal returns:\n",
        "$$\n",
        "\\widehat{AR}_{it} = R_{it} - \\widehat{ER}_{it} = R_{it} - \\hat{\\bbeta}'\\bx_t\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "One issue: $\\widehat{AR}_{it}$ has measurement error. But\n",
        "\n",
        "- Measurement error in dependent variable not a problem if uncorrelated with covariates\n",
        "- If estimation window for $\\hat{\\bbeta}$ large, measurement error likely small\n",
        "\n",
        "### Preparing Data {background=\"#43464B\" visibility=\"uncounted\"}\n",
        "\n",
        "#### Define Time Frames\n",
        "\n",
        "When does treatment turn on? What $T$ to take? \n",
        "\n",
        "- Key public announcement — March 8, 2023 (our $t_0$)\n",
        "- Look for 10 days around ($T=20$)\n",
        "\n",
        ". . .\n"
      ],
      "id": "f9419deb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "event_date = pd.Timestamp(\"2023-03-08\")\n",
        "event_window = pd.Timedelta(days=10)  "
      ],
      "id": "3e186c52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br> \n",
        "\n",
        ". . . \n",
        "\n",
        "For estimation, use long window before SVB collapse:\n"
      ],
      "id": "c44b9ce1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "estimation_window = pd.Timedelta(days=500) \n",
        "start_date = event_date - event_window - estimation_window "
      ],
      "id": "080a7b1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Obtaining Data {.scrollable}\n",
        "\n",
        "Necessary data:\n",
        "\n",
        "- Returns on tickers of interest\n",
        "- Market data for estimating $ER_{it}$ — will use 3-factor Fama-French model\n",
        "\n",
        ". . .\n",
        "\n",
        "Can obtain ticker data from Yahoo Finance directly with  `yfinance` package (abbreviated as `yf`)\n"
      ],
      "id": "71c0d079"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Expand for data call and data preparation\"\n",
        "\n",
        "# Download the tickers and rename columns to only retain ticker names\n",
        "stock_data = yf.download(\n",
        "    tickers, \n",
        "    start=start_date, \n",
        "    end=event_date + 4*event_window,\n",
        "    progress=False,\n",
        ")\n",
        "stock_data = stock_data.iloc[:, 0:len(tickers)]\n",
        "stock_data.columns = (\n",
        "    stock_data.columns.map(lambda col: re.sub(r\"[()\\s']\", \"\", col[1]))\n",
        ")\n",
        "\n",
        "# Calculate daily returns\n",
        "returns = stock_data.pct_change().dropna()*100\n",
        "\n",
        "# Read in FF 3 factor daily data\n",
        "ff_path = Path() / 'data' / 'fama-french-3.csv'\n",
        "fama_french_data = pd.read_csv(ff_path).iloc[:, :-1]\n",
        "# Read the Date column as a date and set it as the index\n",
        "fama_french_data[\"Date\"] = pd.to_datetime(\n",
        "    fama_french_data[\"Date\"], \n",
        "    format=\"%Y-%m-%d\", \n",
        ")\n",
        "fama_french_data = fama_french_data.set_index(\"Date\")\n",
        "\n",
        "# Merge returns and FF data, drop unnecessary data\n",
        "merged_data = pd.concat(\n",
        "    [returns, fama_french_data], \n",
        "    axis=1\n",
        ").dropna(axis=0)"
      ],
      "id": "d735fd72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "\n",
        ":::\n",
        "\n",
        "#### Estimating Abnormal Returns {.scrollable}\n",
        "\n",
        "Estimate outcome variable $AR_{it}$ using Fama-French 3 market model:\n",
        "\n",
        "- Separately regress returns of each $i$ on Fama-French factors over estimation window\n",
        "- Obtained fitted values ($\\widehat{ER}_{it}$) \n",
        "- Compute $\\widehat{AR}_{it}$} and store\n",
        "\n",
        "For contrast, also estimate mean model\n"
      ],
      "id": "b1c35e84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "#| code-fold: true\n",
        "#| code-summary: \"Expand for estimation of abnormal returns\"\n",
        "\n",
        "# Create arrays to hold abnormal returns   \n",
        "abnormal_returns_factor = pd.DataFrame()\n",
        "abnormal_returns_mean = pd.DataFrame()    \n",
        "\n",
        "# Estimate abnormal returns for each \n",
        "for ticker in tickers:\n",
        "    # Estimate the 3-factor abnormal returns\n",
        "    X = merged_data.loc[\n",
        "        merged_data.index < event_date - event_window, \n",
        "        [\"Mkt-RF\", \"SMB\", \"HML\"]\n",
        "    ]   \n",
        "    y = merged_data.loc[\n",
        "        merged_data.index < event_date - event_window, \n",
        "        ticker\n",
        "    ] \n",
        "    X = sm.add_constant(X) \n",
        "    model = sm.OLS(y, X).fit()   \n",
        "\n",
        "    # Compute expected returns during the window\n",
        "    X_event = (\n",
        "        merged_data.loc[\n",
        "            ((merged_data.index >= event_date - event_window) & \n",
        "            (merged_data.index <= event_date + event_window)), \n",
        "            [\"Mkt-RF\", \"SMB\", \"HML\"]\n",
        "        ]\n",
        "    )\n",
        "    X_event = sm.add_constant(X_event)\n",
        "    expected_returns = model.predict(X_event)\n",
        "\n",
        "    # Extract realized returns during the event\n",
        "    event_data = (\n",
        "        merged_data.loc[\n",
        "            ((merged_data.index >= event_date - event_window) & \n",
        "            (merged_data.index <= event_date + event_window)), \n",
        "            ticker\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Abnormal returns are residuals\n",
        "    abnormal_returns_factor[ticker] = event_data - expected_returns\n",
        "    abnormal_returns_mean[ticker] = event_data - y.mean()"
      ],
      "id": "50afe2c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "\n",
        ":::\n",
        "\n",
        "#### Visualizing Average Abnormal Returns\n"
      ],
      "id": "2bf582cf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-causal-es-avg-abnormal-return\n",
        "#| fig-cap: Averages of abnormal returns with 95% pointwise confidence intervals\n",
        "\n",
        "# Combine the two DFs of abnormal returns into a list\n",
        "abnormal_returns_list = [abnormal_returns_mean, abnormal_returns_factor] \n",
        "abnormal_returns_titles = [\"Expected returns: own average\", \"Expected returns: three-factor model\"]\n",
        "\n",
        "# Create a figure\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 4.5))\n",
        "fig.patch.set_facecolor(BG_COLOR)\n",
        "fig.patch.set_edgecolor(\"teal\")\n",
        "fig.patch.set_linewidth(5)\n",
        "\n",
        "# Add plots of average abnormal returns + CIs\n",
        "for method_id, abnormal_df in enumerate(abnormal_returns_list):\n",
        "    # Compute averages and bounds for the confidence interval\n",
        "    effects = pd.DataFrame()\n",
        "    effects[\"estimates\"] = abnormal_df.cumsum().mean(axis=1)\n",
        "    effects[\"ci_upper\"] = effects[\"estimates\"] + 1.96 * np.sqrt(\n",
        "        abnormal_df.var(axis=1).cumsum()\n",
        "    )\n",
        "    effects[\"ci_lower\"] = effects[\"estimates\"] - 1.96 * np.sqrt(\n",
        "        abnormal_df.var(axis=1).cumsum()\n",
        "    )\n",
        "\n",
        "    # Plot the estimates\n",
        "    axs[method_id].plot(\n",
        "        effects.index,\n",
        "        effects[\"estimates\"],\n",
        "        color=\"blue\",\n",
        "        linewidth=2,\n",
        "        label=\"Average abnormal returns\",\n",
        "    )\n",
        "\n",
        "    # Plot the confidence intervals\n",
        "    axs[method_id].fill_between(\n",
        "        effects.index,\n",
        "        effects[\"ci_lower\"],\n",
        "        effects[\"ci_upper\"],\n",
        "        color=\"lightblue\",\n",
        "        alpha=0.5,\n",
        "        label=\"95% CI\",\n",
        "    )\n",
        "\n",
        "    # Add a vertical line on event date\n",
        "    vertical_line_date = event_date\n",
        "    axs[method_id].axvline(\n",
        "        x=vertical_line_date,\n",
        "        color=\"red\",\n",
        "        linestyle=\"--\",\n",
        "        label=\"Event Date\",\n",
        "    )\n",
        "\n",
        "    # Add labels and title\n",
        "    axs[method_id].set_xlabel(\"Date\")\n",
        "    axs[method_id].xaxis.set_tick_params(\n",
        "        which=\"both\",\n",
        "        rotation=76,\n",
        "        labelleft=True,\n",
        "        left=True,\n",
        "    )\n",
        "    axs[method_id].set_title(\n",
        "        abnormal_returns_titles[method_id],\n",
        "        loc=\"left\",\n",
        "    )\n",
        "\n",
        "    # Align y-axes and add grid\n",
        "    axs[method_id].set_ylim([-48, 18])\n",
        "    axs[method_id].grid(True)\n",
        "\n",
        "    axs[method_id].set_facecolor(BG_COLOR)\n",
        "    if method_id == 1:\n",
        "        axs[1].legend()\n",
        "\n",
        "fig.suptitle(\"Averages of abnormal returns per date\", size=18)\n",
        "\n",
        "plt.show()"
      ],
      "id": "fig-causal-es-avg-abnormal-return",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "\n",
        ":::\n",
        "\n",
        "#### Looking For Pretrends\n",
        "\n",
        "@fig-causal-es-avg-abnormal-return suggests idea:\n",
        "\n",
        "- Cannot check no trends assumption for all periods (why?)\n",
        "- But can check pretreatment periods for trends in means\n",
        "\n",
        "<br>\n",
        "\n",
        ". . . \n",
        "\n",
        "@fig-causal-es-avg-abnormal-return: zero mean for $t$ before March 8 — supports no trends\n",
        "\n",
        "\n",
        "### Estimation and Inference {background=\"#43464B\" visibility=\"uncounted\"} \n",
        "\n",
        "#### Preparing Data for Event Study\n",
        "\n",
        "Now need to create $\\bX$ and $\\by$ matrices to apply event study OLS \n",
        "\n",
        "<br>\n",
        "\n",
        ". . . \n",
        "\n",
        "Key challenge: how do $\\bX$ and $\\by$ look like?\n",
        "\n",
        "- Regressors: indicators $D_{it, \\tau}$ of every day after treatment start \n",
        "- Express in tabular form: each row in $\\bX$ contains data on one stock $i$ on one day $t$, columns — $\\widehat{AR}_{it}$ and $D_{it, \\tau}$\n",
        "\n",
        "#### Generate Event Study Data {.scrollable}\n"
      ],
      "id": "db953113"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true \n",
        "#| code-fold: true\n",
        "#| code-summary: \"Expand for construction of data matrices\"\n",
        "\n",
        "# Create an array for day dummies\n",
        "dummy_df = (\n",
        "    pd.get_dummies(\n",
        "        np.maximum(\n",
        "            (abnormal_returns_mean.index - pd.to_datetime(event_date)).days+1, \n",
        "            0,\n",
        "        ), \n",
        "        prefix='day',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Set the index again\n",
        "dummy_df.index = abnormal_returns_factor.index\n",
        "# Drop the column of days preceding the event\n",
        "dummy_df = dummy_df.drop(\"day_0\", axis=1)\n",
        "\n",
        "# Melt abnormal returns data\n",
        "ar_factor_long = abnormal_returns_factor.reset_index().melt(id_vars=\"Date\")\n",
        "ar_factor_long.head()\n",
        "\n",
        "# Merge data\n",
        "ar_factor_days = pd.merge(\n",
        "    ar_factor_long, \n",
        "    dummy_df, \n",
        "    how='left', \n",
        "    left_on='Date', \n",
        "    right_index=True,\n",
        ")\n",
        "# Split into two\n",
        "exog = ar_factor_days.filter(regex=\"day*\", axis=1).astype('float64')\n",
        "exog = sm.add_constant(exog)\n",
        "endog = ar_factor_days.loc[:, \"value\"]\n",
        "\n",
        "# View\n",
        "ar_factor_days.head()"
      ],
      "id": "b0403142",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "#### Event Study OLS {.scrollable}\n",
        "\n",
        "Can now apply the event study estimator \n"
      ],
      "id": "36840b88"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "\n",
        "factor_model = sm.OLS(endog, exog).fit(cov_type=\"HC0\")\n",
        "print(factor_model.summary())"
      ],
      "id": "1816daa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "#### Cumulative Effects {.scrollable}\n",
        "\n",
        "There are (at least) two kinds parameters of interest:\n",
        "\n",
        "- Coefficients $\\beta_{\\tau}$\n",
        "- Cumulative effects up to each given day\n",
        "\n",
        "Can compute cumulative effects and their variances as linear combinations of $\\beta_{\\tau}$\n",
        "\n",
        "#### Computing Cumulative Effects {.scrollable}\n"
      ],
      "id": "cb601dc2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true \n",
        "#| code-fold: true\n",
        "#| code-summary: \"Expand to see computation of cumulative effects\"\n",
        "# Extract coefs and SEs of daily indicators\n",
        "dummy_coefficients = factor_model.params.iloc[1:]  \n",
        "dummy_cov_matrix = factor_model.cov_params().iloc[1:, 1:]  \n",
        "\n",
        "# Compute the cumulative effects\n",
        "cumulative_effects = dummy_coefficients.cumsum()\n",
        "\n",
        "# Compute the standard errors of the cumulative effects\n",
        "cumulative_se = np.zeros(len(cumulative_effects))\n",
        "for t in range(1, len(cumulative_effects) + 1):\n",
        "    # Create a vector of ones up to day t and zeros afterwards\n",
        "    indicator_vector = np.concatenate(\n",
        "        [np.ones(t), np.zeros(len(cumulative_effects) - t)]\n",
        "    )\n",
        "\n",
        "    # Compute the SE of the cumulative effect\n",
        "    cumulative_se[t - 1] = np.sqrt(\n",
        "        indicator_vector @ dummy_cov_matrix @ indicator_vector\n",
        "    )\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results = pd.DataFrame(\n",
        "    {\n",
        "        \"Day\": factor_model.params.index[1:].map(lambda x: x[4:]),\n",
        "        \"Cumulative Effect\": cumulative_effects,\n",
        "        \"SE\": cumulative_se,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Prepend day 0 as a reference\n",
        "day0_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Day\": 0,\n",
        "        \"Cumulative Effect\": 0,\n",
        "        \"SE\": 0,\n",
        "    },\n",
        "    index = np.array(['day_0'])\n",
        ")\n",
        "results = pd.concat([day0_df, results])\n",
        "\n",
        "# Construct confidence intervals\n",
        "results[\"ci_upper\"] = results[\"Cumulative Effect\"] + 1.96 * results[\"SE\"]\n",
        "results[\"ci_lower\"] = results[\"Cumulative Effect\"] - 1.96 * results[\"SE\"]\n",
        "\n",
        "# Set index\n",
        "results.index = abnormal_returns_mean.index[6:]\n",
        "\n",
        "# Print the results\n",
        "print(results)"
      ],
      "id": "4928a1d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "#### Visualizing Cumulative Effects\n"
      ],
      "id": "52bc2fc2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reset the index, plotting will be done against the new index\n",
        "results_reset = results.reset_index()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 4.5))\n",
        "fig.patch.set_facecolor(BG_COLOR)\n",
        "fig.patch.set_edgecolor(\"teal\")\n",
        "fig.patch.set_linewidth(5)\n",
        "\n",
        "# Add vertical line before the event: now use 0.5 as potition\n",
        "ax.axvline(\n",
        "    x=0.5,\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    label=\"Event Date\",\n",
        ")\n",
        "ax.axhline(\n",
        "    y=0,\n",
        "    color=\"gray\",\n",
        "    linestyle=\"--\",\n",
        "    label=\"_nolegend_\",\n",
        ")\n",
        "\n",
        "# Plot the estimates as dots\n",
        "ax.plot(\n",
        "    results_reset.index,\n",
        "    results_reset[\"Cumulative Effect\"],\n",
        "    \"o\",\n",
        "    color=\"blue\",\n",
        "    markersize=8,\n",
        "    label=\"Estimates\",\n",
        ")\n",
        "\n",
        "# Add error bars\n",
        "ax.errorbar(\n",
        "    results_reset.index,\n",
        "    results_reset[\"Cumulative Effect\"],\n",
        "    yerr=[\n",
        "        results_reset[\"Cumulative Effect\"] - results_reset[\"ci_lower\"],\n",
        "        results_reset[\"ci_upper\"] - results_reset[\"Cumulative Effect\"],\n",
        "    ],\n",
        "    fmt=\"o\",\n",
        "    color=\"blue\",\n",
        "    ecolor=\"gray\",\n",
        "    capsize=5,\n",
        "    capthick=2,\n",
        "    label=\"95% CI\",\n",
        ")\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"Average Cumulative Effect on Other Stock Returns\")\n",
        "ax.set_title(\n",
        "    \"Event Study: Collapse of the Silicon Valley Bank (3-factor model)\",\n",
        "    loc=\"left\",\n",
        "    size=14,\n",
        ")\n",
        "ax.set_ylim([-10.5, 4])\n",
        "ax.legend()\n",
        "\n",
        "# Add tick labels using the original dates\n",
        "ax.set_xticks(\n",
        "    results_reset.index,\n",
        "    results_reset[\"Date\"].dt.strftime(\"%Y-%m-%d\"),\n",
        "    rotation=45,\n",
        ")\n",
        "\n",
        "# Recolor and add grid\n",
        "plt.grid(True)\n",
        "ax.set_facecolor(BG_COLOR)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "a45373c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing Joint Zero Effect\n",
        "\n",
        "Can also formally test our null that $H_0: \\beta_{\\tau}=0$ for all $\\tau$\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        ". . .\n",
        "\n",
        "Use Wald test: "
      ],
      "id": "aba021d2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "R = np.concatenate( (np.zeros((8, 1)), np.eye(len(factor_model.params)-1)), axis=1)\n",
        "wald_results = factor_model.wald_test(R,  scalar=True)\n",
        "print(wald_results)"
      ],
      "id": "ebd90fc6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Empirical Conclusions\n",
        "\n",
        "So what is the final conclusion?\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "<div class=\"rounded-box\">\n",
        "\n",
        "Find that collapse of the SVB had significant negative effects on returns over the next 10 days\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "## Recap and Conclusions {background=\"#00100F\"}\n",
        "  \n",
        "#### Recap\n",
        "\n",
        "In this lecture we\n",
        "\n",
        "1. Introduced event studies — the simplest panel causal estimator\n",
        "2. Discussed causal properties under various assumptions of no trends\n",
        "3. Considered dynamic treatment effects\n",
        "4. Expressed event studies as regression\n",
        "5. Did a detailed study on the collapse of the SVB\n",
        "\n",
        "#### Next Questions\n",
        "\n",
        "- What if the assumption of no trends is unreasonable?\n",
        "- What if the treatment is not binary?\n",
        "\n",
        "#### References {.allowframebreaks visibility=\"uncounted\"}\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "222630fa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\moren\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}