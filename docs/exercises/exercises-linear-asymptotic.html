<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Theoretical and applied exercises on asymptotic properties of the OLS estimator: consistency, distributions, measurement error, omitted variable bias.">

<title>Exercises: Vector Linear Model and Asymptotics – Advanced Econometrics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../themes/favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-b53751a350365c71b6c909e95f209ed1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-b1f45ae4a132db6dfc08ad19f9a2d34c.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-b4434866c09ead725b5c0ae22b4ec6c7.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
 

<!-- This is what works with Quarto and MathJax 3+ -->

<script>

  MathJax = {

    tex: {

      tags: 'ams',  // should be 'ams', 'none', or 'all'

      macros: {

        vect: ["\\mathbf{#1}", 1],

        mat: ["\\mathbf{#1}", 1], 



        bA: "\\boldsymbol{A}",

        bB: "\\boldsymbol{B}",

        bC: "\\boldsymbol{C}",

        bD: "\\boldsymbol{D}",

        bE: "\\boldsymbol{E}",

        bF: "\\boldsymbol{F}",

        bG: "\\boldsymbol{G}",

        bH: "\\boldsymbol{H}",

        bI: "\\boldsymbol{I}",

        bJ: "\\boldsymbol{J}",

        bK: "\\boldsymbol{K}",

        bL: "\\boldsymbol{L}",

        bM: "\\boldsymbol{M}",

        bN: "\\boldsymbol{N}",

        bP: "\\boldsymbol{P}",

        bQ: "\\boldsymbol{Q}",

        bR: "\\boldsymbol{R}",

        bS: "\\boldsymbol{S}",

        bT: "\\boldsymbol{T}",

        bU: "\\boldsymbol{U}",

        bV: "\\boldsymbol{V}",

        bW: "\\boldsymbol{W}",

        bX: "\\boldsymbol{X}",

        bY: "\\boldsymbol{Y}",

        bZ: "\\boldsymbol{Z}",

        ba: "\\boldsymbol{a}",

        bb: "\\boldsymbol{b}",

        bc: "\\boldsymbol{c}",

        bd: "\\boldsymbol{d}",

        be: "\\boldsymbol{e}",

        bg: "\\boldsymbol{g}",

        bh: "\\boldsymbol{h}",

        bi: "\\boldsymbol{\\imath}",

        bm: "\\boldsymbol{m}",

        bp: "\\boldsymbol{p}",

        bq: "\\boldsymbol{q}",

        br: "\\boldsymbol{r}",

        bs: "\\boldsymbol{s}",

        bt: "\\boldsymbol{t}",

        bu: "\\boldsymbol{u}",

        bv: "\\boldsymbol{v}",

        bw: "\\boldsymbol{w}",

        bx: "\\boldsymbol{x}",

        by: "\\boldsymbol{y}",



        Acal: "\\mathcal{A}",

        Bcal: "\\mathcal{B}",

        Ccal: "\\mathcal{C}",

        Dcal: "\\mathcal{D}",

        Ecal: "\\mathcal{E}",

        Fcal: "\\mathcal{F}",

        Gcal: "\\mathcal{G}",

        Hcal: "\\mathcal{H}",

        Ical: "\\mathcal{I}",

        Jcal: "\\mathcal{J}",

        Kcal: "\\mathcal{K}",

        Lcal: "\\mathcal{L}",

        Mcal: "\\mathcal{M}",

        Ncal: "\\mathcal{N}",

        Ocal: "\\mathcal{O}",

        Pcal: "\\mathcal{P}",

        Qcal: "\\mathcal{Q}",

        Rcal: "\\mathcal{R}",

        Scal: "\\mathcal{S}",

        Tcal: "\\mathcal{T}",

        Ucal: "\\mathcal{U}",

        Vcal: "\\mathcal{V}",

        Wcal: "\\mathcal{W}",

        Xcal: "\\mathcal{X}",

        Ycal: "\\mathcal{Y}",

        Zcal: "\\mathcal{Z}",



        A: "\\mathbb{A}",

        B: "\\mathbb{B}",

        C: "\\mathbb{C}",

        D: "\\mathbb{D}",

        E: "\\mathbb{E}",

        F: "\\mathbb{F}",

        G: "\\mathbb{G}",

        H: "\\mathbb{H}",

        I: "\\mathbb{I}",

        J: "\\mathbb{J}",

        K: "\\mathbb{K}",

        L: "\\mathbb{L}",

        M: "\\mathbb{M}",

        N: "\\mathbb{N}",

        O: "\\mathbb{O}",

        P: "\\mathbb{P}",

        Q: "\\mathbb{Q}",

        R: "\\mathbb{R}",

        S: "\\mathbb{S}",

        T: "\\mathbb{T}",

        U: "\\mathbb{U}",

        V: "\\mathbb{V}",

        W: "\\mathbb{W}",

        X: "\\mathbb{X}",

        Y: "\\mathbb{Y}",

        Z: "\\mathbb{Z}",



        bAlpha: "\\boldsymbol{\\Alpha}",

        bBeta: "\\boldsymbol{\\beta}",

        bDelta: "\\boldsymbol{\\delta}",

        bEta: "\\boldsymbol{\\eta}",

        bGamma: "\\boldsymbol{\\Gamma}",

        bLambda: "\\boldsymbol{\\Lambda}",

        bOmega: "\\boldsymbol{\\Omega}",

        bPhi: "\\boldsymbol{\\Phi}",

        bPi: "\\boldsymbol{\\Pi}",

        bPsi: "\\boldsymbol{\\Psi}",

        bSigma: "\\boldsymbol{\\Sigma}",

        bTau: "\\boldsymbol{\\tau}",

        bXi: "\\boldsymbol{\\Xi}",

        bbeta: "\\boldsymbol{\\beta}",

        bdelta: "\\boldsymbol{\\delta}",

        blambda: "\\boldsymbol{\\lambda}",

        bmu: "\\boldsymbol{\\mu}",

        bphi: "\\boldsymbol{\\phi}",

        bpi: "\\boldsymbol{\\pi}",

        bpsi: "\\boldsymbol{\\psi}",

        brho: "\\boldsymbol{\\rho}",

        bsigma: "\\boldsymbol{\\sigma}",

        btau: "\\boldsymbol{\\tau}",

        bxi: "\\boldsymbol{\\xi}",

        bEta: "\\boldsymbol{\\eta}",

        bPhi: "\\boldsymbol{\\Phi}",

        bPi: "\\boldsymbol{\\Pi}",

        bPsi: "\\boldsymbol{\\Psi}",

        bXi: "\\boldsymbol{\\Xi}",

        blambda: "\\boldsymbol{\\lambda}",

        bmu: "\\boldsymbol{\\mu}",

        bphi: "\\boldsymbol{\\phi}",

        bpi: "\\boldsymbol{\\pi}",

        bpsi: "\\boldsymbol{\\psi}",

        brho: "\\boldsymbol{\\rho}",

        bsigma: "\\boldsymbol{\\sigma}",

        btheta: "\\boldsymbol{\\theta}",

                   

        curl: ["\\left\\lbrace#1\\right\\rbrace", 1],

        floor: ["\\left\\lfloor#1\\right\\rfloor", 1],

        ceil: ["\\left\\lceil#1\\right\\rceil", 1],

        abs: ["\\left\\lvert#1\\right\\rvert", 1],

        norm: ["\\left\\lVert#1\\right\\rVert", 1],



        avar: "\\mathrm{avar}",

        var: "\\mathrm{var}",

        cov: "\\mathrm{cov}",



        argmin: "\\operatorname*{arg\\,min}",

        argmax: "\\operatorname*{arg\\,max}",

        argsup: "\\operatorname*{arg\\,sup}",

        arginf: "\\operatorname*{arg\\,inf}",

      }

    }

  };

</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Exercises: Vector Linear Model and Asymptotics – Advanced Econometrics">
<meta property="og:description" content="Theoretical and applied exercises on asymptotic properties of the OLS estimator: consistency, distributions, measurement error, omitted variable bias.">
<meta property="og:site_name" content="Advanced Econometrics">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../slides/vector/vector-ols.html">Linear Regression II</a></li><li class="breadcrumb-item"><a href="../exercises/exercises-linear-asymptotic.html">Exercises: Vector Linear Model and Asymptotics</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Advanced Econometrics</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://vladislav-morozov.github.io/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-person-arms-up"></i></a>
    <a href="https://github.com/vladislav-morozov/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/vladislavvmorozov/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-linkedin"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Course Info</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/organizational/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Introduction</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Linear Regression II</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/vector/vector-ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Regression in Vector-Matrix Form</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/vector/identification-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Identification, Estimation and Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/vector/ols-consistency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Consistency of the OLS Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/vector/ols-limit-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Limit Distribution of the OLS Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/exercises-linear-asymptotic.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Exercises: Vector Linear Model and Asymptotics</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Asymptotic Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/vector/ols-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inference I: Linear Hypotheses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../slides/vector/ols-delta-method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inference II: Nonlinear Hypotheses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/exercises-linear-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises: Asymptotic Inference</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#theoretical-exercises" id="toc-theoretical-exercises" class="nav-link active" data-scroll-target="#theoretical-exercises">Theoretical Exercises</a>
  <ul class="collapse">
  <li><a href="#regressing-fitted-values" id="toc-regressing-fitted-values" class="nav-link" data-scroll-target="#regressing-fitted-values">Regressing Fitted Values</a></li>
  <li><a href="#inconsistency-of-ols-despite-strict-exogeneity" id="toc-inconsistency-of-ols-despite-strict-exogeneity" class="nav-link" data-scroll-target="#inconsistency-of-ols-despite-strict-exogeneity">Inconsistency of OLS Despite Strict Exogeneity</a></li>
  <li><a href="#ratio-slope-estimator" id="toc-ratio-slope-estimator" class="nav-link" data-scroll-target="#ratio-slope-estimator">Ratio Slope Estimator</a></li>
  <li><a href="#limit-of-the-ridge-estimator" id="toc-limit-of-the-ridge-estimator" class="nav-link" data-scroll-target="#limit-of-the-ridge-estimator">Limit of the Ridge Estimator</a></li>
  <li><a href="#measurement-error-revisited" id="toc-measurement-error-revisited" class="nav-link" data-scroll-target="#measurement-error-revisited">Measurement Error Revisited</a></li>
  <li><a href="#omitted-variable-bias-revisited" id="toc-omitted-variable-bias-revisited" class="nav-link" data-scroll-target="#omitted-variable-bias-revisited">Omitted Variable Bias Revisited</a></li>
  </ul></li>
  <li><a href="#applied-exercises" id="toc-applied-exercises" class="nav-link" data-scroll-target="#applied-exercises">Applied Exercises</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/vladislav-morozov/econometrics-2/edit/main/src/exercises/exercises-linear-asymptotic.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/vladislav-morozov/econometrics-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../slides/vector/vector-ols.html">Linear Regression II</a></li><li class="breadcrumb-item"><a href="../exercises/exercises-linear-asymptotic.html">Exercises: Vector Linear Model and Asymptotics</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Exercises: Vector Linear Model and Asymptotics</h1>
</div>

<div>
  <div class="description">
    Theoretical and applied exercises on asymptotic properties of the OLS estimator: consistency, distributions, measurement error, omitted variable bias.
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="theoretical-exercises" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-exercises">Theoretical Exercises</h2>
<section id="regressing-fitted-values" class="level3">
<h3 class="anchored" data-anchor-id="regressing-fitted-values">Regressing Fitted Values</h3>
<p>Suppose that we observe data <span class="math inline">\((Y_1, \bX_1), \dots (Y_N, \bX_N)\)</span>. Let <span class="math inline">\(\bY\)</span> be the <span class="math inline">\(N\times 1\)</span> vector of outcomes, <span class="math inline">\(\bX\)</span> be the data matrix, and suppose that <span class="math inline">\(\bX'\bX\)</span> is invertible.</p>
<p>Let the vector <span class="math inline">\(\hat{\bY}\)</span> of fitted values and the vector <span class="math inline">\(\hat{\be}\)</span> of errors be given by <span class="math display">\[
\begin{aligned}
\hat{\bY} &amp; = \bX\hat{\bbeta},\\
\hat{\be} &amp; = \bY- \hat{\bY},
\end{aligned}
\]</span> where <span class="math inline">\(\hat{\bbeta}\)</span> is the OLS estimator.</p>
<p>Find the OLS coefficient vector from</p>
<ol type="1">
<li>Regressing <span class="math inline">\(\hat{Y}_i\)</span> on <span class="math inline">\(\bX_i\)</span>.</li>
<li>Regressing <span class="math inline">\(\hat{e}_i\)</span> on <span class="math inline">\(\bX_i\)</span>.</li>
</ol>
<p>In both cases, express the OLS estimator in terms of <span class="math inline">\(\bY\)</span> and <span class="math inline">\(\bX\)</span>. Then express it in terms of <span class="math inline">\((Y_i, \bX_i)\)</span>, <span class="math inline">\(i=1, \dots, N\)</span>.</p>
<details>
<summary>
Click to see the solution
</summary>
<p><em>First subquestion</em>: First consider the question of regressing <span class="math inline">\(\hat{\bY}\)</span> on <span class="math inline">\(\bX\)</span>. Let <span class="math inline">\(\tilde{\bbeta}\)</span> be the OLS estimator of regressing <span class="math inline">\(\hat{\bY}\)</span> on <span class="math inline">\(\bX\)</span>. We can use the usual formula for OLS, but replace <span class="math inline">\(\bY\)</span> with <span class="math inline">\(\hat{\bY}\)</span>. We can then use the definition of <span class="math inline">\(\hat{\bY}\)</span> and <span class="math inline">\(\hat{\bbeta}\)</span> to express the coefficients in terms of the original data: <span class="math display">\[
\begin{aligned}
\tilde{\bbeta} &amp; = (\bX'\bX)^{-1}\bX'\hat{\bY} = (\bX'\bX)^{-1}\bX'\bX\hat{\bbeta} \\
&amp; = \hat{\bbeta} = (\bX'\bX)^{-1}\bX\bY = \left(\sum_{i=1}^N \bX_i\bX_i' \right)^{-1}\sum_{i=1}^N\bX_iY_i,
\end{aligned}
\]</span> One way to interpret the above result is that applying OLS more than once does not change anything. The first application already extracts all the information that can be linearly explained by <span class="math inline">\(\bX\)</span> (a property sometimes called <em>idempotency</em>).</p>
<p><br></p>
<p><em>Second subquestion</em>: We can proceed similarly with <span class="math inline">\(\hat{\be}\)</span>. Let <span class="math inline">\(\check{\bbeta}\)</span> be the OLS estimator for regressing <span class="math inline">\(\hat{\bbeta}\)</span> on <span class="math inline">\(\bX\)</span>. We can again use the general expression for the OLS estimator and substitute the definition of <span class="math inline">\(\hat{\bbeta}\)</span>: <span class="math display">\[
\begin{aligned}
\check{\bbeta} &amp; = (\bX'\bX)^{-1}\bX'\hat{\be} = (\bX'\bX)^{-1}\bX'(\bY-\hat{\bY})\\
&amp; = \hat{\bbeta} -\tilde{\bbeta} = \hat{\bbeta}- \hat{\bbeta}\\
&amp; = 0,
\end{aligned}
\]</span> where we have used the first result of the problem.</p>
</details>
</section>
<section id="inconsistency-of-ols-despite-strict-exogeneity" class="level3">
<h3 class="anchored" data-anchor-id="inconsistency-of-ols-despite-strict-exogeneity">Inconsistency of OLS Despite Strict Exogeneity</h3>
<p>Let <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span> be scalar variables. Let <span class="math inline">\(X_i\)</span> satisfy <span id="eq-pset1-p2-x"><span class="math display">\[
X_i = \begin{cases}
1, &amp; i = 1, \\
0, &amp; i &gt; 1.
\end{cases}
\tag{1}\]</span></span></p>
<ol type="1">
<li>Suppose we have a sample of <span class="math inline">\(N\)</span> units: <span class="math inline">\((Y_1, X_1), \dots, (Y_N, X_N)\)</span>. Can we compute the OLS estimator for regressing <span class="math inline">\(Y_i\)</span> on <span class="math inline">\(X_i\)</span> (without a constant)? If yes, express the estimator in terms of <span class="math inline">\((Y_i, X_i)\)</span>, <span class="math inline">\(i=1,\dots, N\)</span>. If not, explain why.</li>
<li>Suppose that <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span> are linked through the linear causal model <span id="eq-pset1-p2-causal"><span class="math display">\[
Y_i^x = \beta x + U_i,
\tag{2}\]</span></span> where <span class="math inline">\(Y_i^x\)</span> is a potential outcome, <span class="math inline">\(U_i\)</span> is independent of <span class="math inline">\(X_i\)</span> with <span class="math inline">\(\E[U_i]=0\)</span>. Why does the OLS estimator of <span class="math inline">\(\beta\)</span> not converge to <span class="math inline">\(\beta\)</span> without stronger assumptions on <span class="math inline">\(U_i\)</span>? Informally, which of the conditions of our consistency results fail?</li>
<li>Provide an informal empirical interpretation of the above data-generating process for <span class="math inline">\(X_i\)</span>.</li>
</ol>
<details>
<summary>
Click to see the solution
</summary>
<p><em>First subquestion</em>: The computability of the OLS estimator is determined by one key question: is <span class="math inline">\(\bX'\bX\)</span> invertible? If <span class="math inline">\(\bX'\bX\)</span> is invertible, then the answer is positive.</p>
<p>In this case, there is only one scalar covariate. <span class="math inline">\(\bX'\bX\)</span> is itself then scalar (<span class="math inline">\(1\times 1\)</span>) and given by <span class="math display">\[
\bX'\bX = \sum_{i=1}^N X_i^2
\]</span> By <a href="#eq-pset1-p2-x" class="quarto-xref">Equation&nbsp;1</a>, we have that <span class="math inline">\(\sum_{i=1}^N X_i^2=1\)</span>, which is invertible. It follows that we can compute <span class="math inline">\(\hat{\beta}=(\bX'\bX)^{-1}\bX'\bY\)</span>: <span id="eq-pset1-p2-beta"><span class="math display">\[
\hat{\beta} = (\bX'\bX)^{-1}\bX'\bY = \dfrac{\sum_{i=1}^N X_iY_i}{\sum_{i=1}^N X_i^2} = Y_1.
\tag{3}\]</span></span></p>
<p><br></p>
<p><em>Second subquestion:</em> To answer this question formally, we use the same technique we use in the lectures — substituting the underlying model into the estimator. By <a href="#eq-pset1-p2-causal" class="quarto-xref">Equation&nbsp;2</a>, the realized outcomes satisfy <span class="math display">\[
Y_i = \beta X_i + U_i
\]</span></p>
<p>We substitute this expression for realized values into the OLS estimator (<a href="#eq-pset1-p2-beta" class="quarto-xref">3</a>) to obtain <span class="math display">\[
\hat{\beta} = \beta + U_1,
\]</span> where we have used that <span class="math inline">\(X_1 =1\)</span> by <a href="#eq-pset1-p2-x" class="quarto-xref">Equation&nbsp;1</a>.</p>
<p>We now see that the value of <span class="math inline">\(\hat{\beta}\)</span> does not depend on sample size <span class="math inline">\(N\)</span>. The full value of <span class="math inline">\(U_1\)</span> will always be present in <span class="math inline">\(\hat{\beta}\)</span>: as <span class="math inline">\(N\to\infty\)</span> <span class="math display">\[
\hat{\beta} \xrightarrow{p} \beta + U_1
\]</span> The only case where <span class="math inline">\(\hat{\beta}\xrightarrow{p}\beta\)</span> is when <span class="math inline">\(U_1=0\)</span> — an additional stronger condition.</p>
<p>Which conditions of our consistency results fail? There are two conditions that hold:</p>
<ul>
<li>Orthogonality: <span class="math inline">\(\E[X_iU_i] =0\)</span> holds.</li>
<li>Independence of units</li>
</ul>
<p>There are two conditions that do not hold:</p>
<ul>
<li>Identical distributions: unit 1 is different to the rest.</li>
<li>Invertibility of the limit of <span class="math inline">\(N^{-1}\sum_{i=1}^N\bX_i\bX_i'\)</span>. By <a href="#eq-pset1-p2-x" class="quarto-xref">Equation&nbsp;1</a>, this sum is equal to <span class="math inline">\(N^{-1}\to 0\)</span>.</li>
</ul>
<p>Of these two failing conditions, the first one is usually not a big issue. It concerns only a single point, and in general we have tools for handling non-identical distributions. It is the second condition that creates a problem in the limit.</p>
<p>The message of this problem is that we need two invertibility conditions: the sample condition (on <span class="math inline">\(\bX'\bX\)</span>) and the population one (on <span class="math inline">\(\E[\bX_i\bX_i']\)</span>). These conditions play different roles. Each can fail, while the other condition is true.</p>
<p><br></p>
<p><em>Third subquestion</em>: we can imagine a simple experiment in which the subjects have arrived to the lab in a random order, independently of their characteristics. However, there is only one real treatment, which is given to the first unit. Everyone else receives a placebo.</p>
</details>
</section>
<section id="ratio-slope-estimator" class="level3">
<h3 class="anchored" data-anchor-id="ratio-slope-estimator">Ratio Slope Estimator</h3>
<p>Let <span class="math inline">\(X_i\)</span> and <span class="math inline">\(U_i\)</span> be scalar random variables. Suppose that <span class="math inline">\(X_i\)</span> satisfies <span class="math inline">\(X_i\geq c&gt;0\)</span> for some <span class="math inline">\(c\)</span> (strictly positive and bounded away from 0). Let <span class="math inline">\(Y_i\)</span> be some outcome. Suppose that the following linear causal model holds: the potential outcome <span class="math inline">\(Y_i^x\)</span> is determined as <span id="eq-pset1-p3-causal"><span class="math display">\[
Y_i^x = \beta x + U_i.
\tag{4}\]</span></span> The realized outcome <span class="math inline">\(Y_i\)</span> is determined as <span class="math inline">\(Y_i = Y_i^{X_i}\)</span>.</p>
<p>Consider the following estimator for <span class="math inline">\(\beta\)</span>: <span class="math display">\[
\tilde{\beta} = \dfrac{1}{N}\sum_{i=1}^N \dfrac{Y_i}{X_i}.
\]</span></p>
<ol type="1">
<li>Propose conditions under which <span class="math inline">\(\tilde{\beta}\)</span> is consistent for <span class="math inline">\(\beta\)</span> and prove consistency.</li>
<li>Derive the asymptotic distribution of <span class="math inline">\(\tilde{\beta}\)</span>. Describe any additional assumptions you make.</li>
<li>Now suppose that the causal model allows heterogeneous effects: <span id="eq-pset1-p3-causal-het"><span class="math display">\[
Y_i^x = \beta_i x + U_i.
\tag{5}\]</span></span> Under which conditions does <span class="math inline">\(\tilde{\beta}\)</span> consistently estimate <span class="math inline">\(\E[\beta_i]\)</span>?</li>
</ol>
<details>
<summary>
Click to see the solution
</summary>
<p><em>First subquestion</em>: we again use the key technique — substituting the true model into the estimator. By <a href="#eq-pset1-p3-causal" class="quarto-xref">Equation&nbsp;4</a>, the outcome <span class="math inline">\(Y_i\)</span> satisfies <span class="math display">\[
Y_i = \beta X_i + U_i.
\]</span> We can substitute this expression into <span class="math inline">\(\tilde{\beta}\)</span> to obtain <span class="math display">\[
\tilde{\beta} = \dfrac{1}{N}\sum_{i=1}^N \dfrac{Y_i}{X_i} = \beta+ \dfrac{1}{N}\sum_{i=1}^N \dfrac{U_i}{X_i}
\]</span> The law of large number applies to the sum on the right hand side if</p>
<ol type="1">
<li><span class="math inline">\((X_i, U_i)\)</span> are IID.</li>
<li><span class="math inline">\(\E[U_i/X_i]\)</span> exists.</li>
</ol>
<p>We make these assumptions. Then by the law of large numbers: <span class="math display">\[
\dfrac{1}{N}\sum_{i=1}^N \dfrac{U_i}{X_i}\xrightarrow{p} \E\left[ \dfrac{U_i}{X_i} \right].
\]</span> By the continuous mapping theorem: <span class="math display">\[
\tilde{\beta} \xrightarrow{p} \beta + \E\left[ \dfrac{U_i}{X_i} \right].
\]</span> <span class="math inline">\(\tilde{\beta}\)</span> is consistent for <span class="math inline">\(\beta\)</span> if</p>
<ol start="3" type="1">
<li><span class="math inline">\(\E[U_i/X_i]=0\)</span> (note that it is sufficient that <span class="math inline">\(\E[U_i|X_i]=0\)</span> for this condition, why?).</li>
</ol>
<p>We conclude that <span class="math inline">\(\tilde{\beta}\)</span> is consistent for <span class="math inline">\(\beta\)</span> under assumptions (1)-(3).</p>
<p><br></p>
<p><em>Second subquestion</em>: to study the asymptotic distribution, we keep the above conditions (1)-(3). Under these conditions (especially (3)) we note that <span id="eq-pset1-p3-sampling-error"><span class="math display">\[
\begin{aligned}
\tilde{\beta} - \beta &amp; = \dfrac{1}{N}\sum_{i=1}^N \dfrac{U_i}{X_i} \\
&amp; = \dfrac{1}{N}\sum_{i=1}^N \dfrac{U_i}{X_i} - \E\left[\dfrac{U_i}{X_i}\right].
\end{aligned}
\tag{6}\]</span></span> The bottom line is in the form used in the central limit theorem: sample average minus population average. We can then apply the central limit theorem provided the following assumption holds:</p>
<ol start="4" type="1">
<li>Finite second moments: <span class="math inline">\(\E[U_i^2/X_i^2]&lt;\infty\)</span>.</li>
</ol>
<p>Then by the central limit theorem it holds that <span class="math display">\[
\sqrt{N}\left(  \dfrac{1}{N}\sum_{i=1}^N \dfrac{U_i}{X_i} - \E\left[\dfrac{U_i}{X_i}\right] \right)\xrightarrow{d} N\left(0, \E\left[\dfrac{U_i^2}{X_i^2} \right] \right).
\]</span></p>
<p>By <a href="#eq-pset1-p3-sampling-error" class="quarto-xref">Equation&nbsp;6</a> we conclude that, if assumptions (1)-(4) hold, then <span class="math display">\[
\sqrt{N}\left(\tilde{\beta}- \beta \right)\xrightarrow{d} N\left(0, \E\left[\dfrac{U_i^2}{X_i^2} \right] \right).
\]</span></p>
<p><br></p>
<p><em>Third subquestion</em>: we again start by substituting the causal model into the estimator. Under <a href="#eq-pset1-p3-causal-het" class="quarto-xref">Equation&nbsp;5</a> the outcome satisfies <span class="math display">\[
Y_i = \beta_i X_i + U_i.
\]</span> Then <span class="math inline">\(\tilde{\beta}\)</span> can be written as <span id="eq-pset1-p3-sampling-error-het"><span class="math display">\[
\tilde{\beta} = \dfrac{1}{N}\sum_{i=1}^N \beta_i +  \dfrac{1}{N}\sum_{i=1}^N \dfrac{U_i}{X_i}.
\tag{7}\]</span></span> The second sum in <a href="#eq-pset1-p3-sampling-error-het" class="quarto-xref">Equation&nbsp;7</a> can be handled as in the first subquestion using assumptions (1)-(3). The first sum satisfies <span class="math display">\[
\dfrac{1}{N}\sum_{i=1}^N \beta_i  \xrightarrow{p} \E[\beta_i]
\]</span> by the law of large numbers provided</p>
<ol start="5" type="1">
<li><span class="math inline">\(\E[\beta_i]\)</span> exists.</li>
</ol>
<p>We conclude by the continuous mapping theorem (where do we apply it?) that <span class="math inline">\(\tilde{\beta}\)</span> is consistent for <span class="math inline">\(\E[\beta_i]\)</span> under conditions (1)-(3) and (5).</p>
<p>Note that this consistency result does not restrict the dependence between <span class="math inline">\(\beta_i\)</span> and <span class="math inline">\(X_i\)</span>. This is in contrast to the behavior of the OLS estimator (see lectures).</p>
</details>
</section>
<section id="limit-of-the-ridge-estimator" class="level3">
<h3 class="anchored" data-anchor-id="limit-of-the-ridge-estimator">Limit of the Ridge Estimator</h3>
<p>Let the outcome <span class="math inline">\(Y_i\)</span>, the covariates <span class="math inline">\(\bX_i\)</span>, and an unobserved component <span class="math inline">\(U_i\)</span> be linked through the linear causal model <span class="math display">\[
Y_i^{\bx} = \bx'\bbeta + U_i
\]</span> Suppose that we observe an IID sample of data on <span class="math inline">\(Y_i, \bX_i\)</span>.</p>
<p>Define the ridge estimator <span class="math inline">\(\tilde{\bbeta}\)</span> as <span class="math display">\[
\tilde{\bbeta} = (\bX'\bX+ \lambda_N \bI_k)^{-1}\bX'\bY,
\]</span> where <span class="math inline">\(\lambda_N\)</span> is some non-negative number, <span class="math inline">\(\bI_k\)</span> is the <span class="math inline">\(k\times k\)</span> identity matrix, and we assume that <span class="math inline">\((\bX'\bX+ \lambda_N \bI_k)\)</span> is invertible.</p>
<ol type="1">
<li>Suppose that <span class="math inline">\(\bX_i\)</span> is scalar. Show that <span class="math inline">\(\abs{\tilde{\bbeta}}\leq \abs{\hat{\bbeta}}\)</span>, where <span class="math inline">\(\hat{\bbeta}\)</span> is the OLS estimator (in words, the ridge estimator is always weakly closer to 0 than the OLS estimator — it is “shrunk” to zero).</li>
<li>Suppose that <span class="math inline">\(\lambda_N = cN\)</span> for some fixed <span class="math inline">\(c\geq 0\)</span>. Find the probability limit of <span class="math inline">\(\tilde{\bbeta}\)</span>. State explicitly any moment assumptions you make. When is <span class="math inline">\(\tilde{\bbeta}\)</span> consistent for <span class="math inline">\(\bbeta\)</span>?</li>
<li><em>(Optional)</em>: prove that ridge estimator satisfies <span class="math display">\[
\tilde{\bbeta} = \argmin_{\bb} \sum_{i=1}^N (Y_i - \bX_i'\bb)^{2} + \lambda \norm{\bb}^2
\]</span> Hint: use the same approach as we used to derive the OLS estimator.</li>
</ol>
<details>
<summary>
Click to see the solution
</summary>
<p><em>First subquestion</em>: in the scalar case we can write the two estimators as <span class="math display">\[
\begin{aligned}
\hat{\bbeta} &amp; = \dfrac{\sum_{i=1}^N X_i Y_i }{\sum_{i=1}^N X_i^2},\\
\tilde{\bbeta} &amp; = \dfrac{\sum_{i=1}^N X_i Y_i}{\sum_{i=1}^N X_i^2 + \lambda_N}.
\end{aligned}
\]</span> We can then divide the ridge estimator by the OLS estimator: <span class="math display">\[
\dfrac{\tilde{\bbeta}}{\hat{\bbeta}} = \dfrac{\sum_{i=1}^N X_i^2}{ \sum_{i=1}^N X_i^2 + \lambda_N } \leq 1.
\]</span> The desired inequality follows.</p>
<p><br></p>
<p><em>Second subquestion</em>: for the second subquestion, we again start by substituting the model into the estimator: <span id="eq-pset1-p4-sampling-error"><span class="math display">\[
\begin{aligned}
\tilde{\bbeta} &amp; = (\bX'\bX+ \lambda_N \bI_k)^{-1}\bX'\bY\\
&amp; = \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i' + c\bI_k\right)^{-1} \dfrac{1}{N}\sum_{i=1}^N \bX_iY_i\\
&amp; = \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i' + c\bI_k\right)^{-1} \dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'\bbeta\\
&amp; \quad + \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i' + c\bI_k\right)^{-1} \dfrac{1}{N}\sum_{i=1}^N \bX_i U_i
\end{aligned}
\tag{8}\]</span></span> We now only need to handle the individual averages in the above expression.</p>
<p>First, we assume that</p>
<ul>
<li><span class="math inline">\(\E[\bX_i\bX_i']\)</span> and <span class="math inline">\(\E[\bX_i'U_i]\)</span> exist</li>
</ul>
<p>Then by the law of large number it holds that <span class="math display">\[
\begin{aligned}
\dfrac{1}{N}\sum_{i=1}^N \bX_i \bX_i' &amp; \xrightarrow{p} \E[\bX_i\bX_i'], \\
\dfrac{1}{N}\sum_{i=1}^N \bX_i U_i &amp; \xrightarrow{p} \E[\bX_iU_i] .
\end{aligned}
\]</span> By the continuous mapping theorem it also follows that <span id="eq-pset1-p4-leading-term"><span class="math display">\[
\dfrac{1}{N}\sum_{i=1}^N \bX_i \bX_i' + c\bI_i \xrightarrow{p} \E[\bX_i\bX_i'] + c\bI_k.
\tag{9}\]</span></span></p>
<p>Second, to handle the leading terms in <a href="#eq-pset1-p4-sampling-error" class="quarto-xref">Equation&nbsp;8</a>, we also assume that</p>
<ul>
<li><span class="math inline">\(\E[\bX_i\bX_i'] + c\bI_k\)</span> is invertible</li>
</ul>
<p>Then by the continuous mapping theorem and <a href="#eq-pset1-p4-leading-term" class="quarto-xref">Equation&nbsp;9</a> it holds that <span class="math display">\[
\left(\dfrac{1}{N}\sum_{i=1}^N \bX_i \bX_i' + c\bI_k\right)^{-1} \xrightarrow{p} \left(\E[\bX_i\bX_i'] + c\bI_k\right)^{-1}.
\]</span></p>
<p>Combining the above arguments together and applying the continuous mapping theorem, we conclude that <span class="math display">\[
\begin{aligned}
\tilde{\bbeta} &amp; \xrightarrow{p}  \left(\E[\bX_i\bX_i'] + c\bI_k\right)^{-1} \E[\bX_i\bX_i']\bbeta
\\
&amp; \quad +  \left(\E[\bX_i\bX_i'] + c\bI_k\right)^{-1} \E[\bX_iU_i].
\end{aligned}
\]</span> We conclude that <span class="math inline">\(\tilde{\bbeta}\)</span> is consistent for <span class="math inline">\(\bbeta\)</span> if <span class="math inline">\(c=0\)</span> and <span class="math inline">\(\E[\bX_iU_i]=0\)</span>.</p>
<p><br></p>
</details>
<p>Why would one use <span class="math inline">\(\tilde{\bbeta}\)</span>? Note that <span class="math inline">\(\bX'\bX + c\bI_k\)</span> is invertible if <span class="math inline">\(c&gt;0\)</span>, regardless of invertibility of <span class="math inline">\(\bX'\bX\)</span>. This means that <span class="math inline">\(\tilde{\bbeta}\)</span> can be computed even if the OLS estimator cannot. A leading case is <em>high-dimensional</em> regression, where the number of regressors <span class="math inline">\(k\)</span> exceeds the number <span class="math inline">\(N\)</span> of data points. See section 6.2.1 in <span class="citation" data-cites="James2023IntroductionStatisticalLearning">James et al. (<a href="#ref-James2023IntroductionStatisticalLearning" role="doc-biblioref">2023</a>)</span> about the ridge estimator and regularization techniques in general. We will discuss some of these ideas later in the class.</p>
</section>
<section id="measurement-error-revisited" class="level3">
<h3 class="anchored" data-anchor-id="measurement-error-revisited">Measurement Error Revisited</h3>
<p>Let the outcome <span class="math inline">\(Y_i\)</span>, the covariates <span class="math inline">\(\bX_i\)</span>, and an unobserved component <span class="math inline">\(U_i\)</span> be linked through the linear causal model <span class="math display">\[
Y_i^{\bx} = \bx'\bbeta + U_i
\]</span> Suppose that our data is IID, that <span class="math inline">\(\E[\bX_iU_i]=0\)</span>, the second moments of the data are finite, and that <span class="math inline">\(\E[\bX_i\bX_i']\)</span> is invertible.</p>
<p>Suppose that we do not observe the true <span class="math inline">\(Y_i\)</span>, but instead a mismeasured version <span class="math inline">\(Y_i^*= Y_i + V_i\)</span>, where the measurement error <span class="math inline">\(V_i\)</span> is mean zero, independent of <span class="math inline">\((X_i, U_i)\)</span>, and has finite second moments.</p>
<ol type="1">
<li>Show that the OLS estimator for the regression of <span class="math inline">\(Y_i^*\)</span> on <span class="math inline">\(\bX_i\)</span> is consistent for <span class="math inline">\(\bbeta\)</span>.</li>
<li>Derive the asymptotic distribution of the above OLS estimator. Express the asymptotic variance in terms of moments involving <span class="math inline">\(V_i\)</span> and <span class="math inline">\(U_i\)</span>. Interpret the result: how does the measurement error in <span class="math inline">\(\bX\)</span> affect the asymptotic variance of the OLS estimator (increase, decrease, unchanged, unclear)?</li>
</ol>
<p>Now suppose that we do observe <span class="math inline">\(Y_i\)</span>, but we do not observe <span class="math inline">\(\bX_i\)</span>. Instead, we only see a mismeasured version <span class="math inline">\(\bX_i^*= \bX_i + \bV_i\)</span>, where the measurement error <span class="math inline">\(\bV_i\)</span> is mean zero, independent of <span class="math inline">\((\bX_i, U_i)\)</span>, and has finite second moments.</p>
<ol start="3" type="1">
<li>Compute the limit of the OLS estimator in the regression of <span class="math inline">\(Y_i\)</span> on <span class="math inline">\(\bX_i^*\)</span> in terms of <span class="math inline">\((Y_i, \bX_i, V_i, U_i)\)</span>. Is this estimator consistent for <span class="math inline">\(\bbeta\)</span>? If so, under which conditions?</li>
</ol>
<p>Compare the two cases of measurement error.</p>
<details>
<summary>
Click to see the solution
</summary>
<p><em>First subquestion</em>: we begin by writing out the OLS estimator, and substituting the causal and measurement models: <span id="eq-pset1-p5-sampling-error"><span class="math display">\[
\begin{aligned}
\hat{\bbeta} &amp; = \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i' \right)^{-1} \dfrac{1}{N} \sum_{i=1}^N \bX_iY_i^* \\
&amp; = \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i' \right)^{-1} \dfrac{1}{N} \sum_{i=1}^N \bX_i(Y_i + V_i)\\
&amp; = \bbeta +\left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i' \right)^{-1} \dfrac{1}{N} \sum_{i=1}^N \bX_i (U_i+V_i)
\end{aligned}
\tag{10}\]</span></span></p>
<p>We handle the individual averages using the law of large numbers and combine the results using the continuous mapping theorem.</p>
<p>By the assumptions of the problem and the law of large numbers it holds that <span class="math display">\[
\begin{aligned}
\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i' &amp; \xrightarrow{p} \E[\bX_i\bX_i'], \\
\dfrac{1}{N}\sum_{i=1}^N \bX_iU_i &amp; \xrightarrow{p} \E[\bX_iU_i] =0, \\
\dfrac{1}{N}\sum_{i=1}^N \bX_iV_i &amp; \xrightarrow{p} \E[\bX_iV_i] =\E[\bX_i]\E[V_i]=0, \\
\end{aligned}
\]</span> where we use the independence of <span class="math inline">\(V_i\)</span> in the last line.</p>
<p>By the continuous mapping theorem and assumption that <span class="math inline">\(\E[\bX_i\bX_i']\)</span> is invertible it holds that <span id="eq-pset1-p5-inverse"><span class="math display">\[
\left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'\right)^{-1}  \xrightarrow{p} \left( \E[\bX_i\bX_i']\right)^{-1}.
\tag{11}\]</span></span></p>
<p>By the continuous mapping theorem and the above results we conclude that <span class="math display">\[
\hat{\bbeta} \xrightarrow{p} \bbeta.
\]</span></p>
<p><br></p>
<p><em>Second subquestion</em>: to analyze the asymptotic distribution, we go to the last line in <a href="#eq-pset1-p5-sampling-error" class="quarto-xref">Equation&nbsp;10</a>. By the assumptions of the problem it holds that <span class="math display">\[
\E[X_i(U_i+V_i)] = 0.
\]</span> Accordingly, <span class="math display">\[
\begin{aligned}
&amp; \dfrac{1}{N} \sum_{i=1}^N \bX_i (U_i+V_i) \\
&amp; = \dfrac{1}{N} \sum_{i=1}^N \bX_i (U_i+V_i) - \E[\bX_i(U_i+V_i)].
\end{aligned}
\]</span> We have identified a term to which we can apply the central limit theorem. We can now proceed as with the usual OLS estimator without measurement error in <span class="math inline">\(Y_i\)</span>.</p>
<ol type="1">
<li><p>By the central limit theorem it holds that <span class="math display">\[
\begin{aligned}
&amp; \dfrac{1}{\sqrt{N}} \sum_{i=1}^N \bX_i (U_i+V_i) \\
&amp; \sqrt{N}\left( \dfrac{1}{N} \sum_{i=1}^N \bX_i (U_i+V_i) - \E[\bX_i(U_i+V_i)] \right) \\
&amp; \xrightarrow{d} N(0, \E[(U_i+V_i)^2\bX_i\bX_i'])
\end{aligned}
\]</span></p></li>
<li><p>By <a href="#eq-pset1-p5-inverse" class="quarto-xref">Equation&nbsp;11</a> it holds that <span class="math display">\[
\left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'\right)^{-1}  \xrightarrow{p} \left( \E[\bX_i\bX_i']\right)^{-1}.
\]</span></p></li>
<li><p>By (1)-(2), Slutsky’s theorem, and the properties of variance it follows that <span class="math display">\[
\begin{aligned}
&amp; \sqrt{N}(\hat{\bbeta}-\bbeta)\\
&amp; = \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'\right)^{-1} \dfrac{1}{\sqrt{N} } \sum_{i=1}^N \bX_i (U_i+V_i)   \\
&amp;  \xrightarrow{d} N\left(0,  \left( \E[\bX_i\bX_i']\right)^{-1} \E[(U_i+V_i)^2\bX_i\bX_i']\left( \E[\bX_i\bX_i']\right)^{-1} \right)
\end{aligned}
\]</span></p></li>
</ol>
<p>We can further examine the asymptotic variance. First consider the middle component: <span class="math display">\[
\begin{aligned}
&amp;\E[(U_i+V_i)^2\bX_i\bX_i'] \\
&amp; = \E[U_i^2 \bX_i\bX_i'] + 2\E[V_i]\E[U_i\bX_i\bX_i'] + \E[V_i^2]\E[\bX_i\bX_i'] \\
&amp; = \E[U_i^2 \bX_i\bX_i'] + \E[V_i^2]\E[\bX_i\bX_i'],
\end{aligned}
\]</span> where we have used the properties of <span class="math inline">\(V_i\)</span>.</p>
<p>Substituting this expression back into the asymptotic variance expression gives us <span class="math display">\[
\begin{aligned}
&amp; \left( \E[\bX_i\bX_i']\right)^{-1} \E[(U_i+V_i)^2\bX_i\bX_i']\left( \E[\bX_i\bX_i']\right)^{-1} \\
&amp; = \left( \E[\bX_i\bX_i']\right)^{-1} \E[U_i^2\bX_i\bX_i']\left( \E[\bX_i\bX_i']\right)^{-1} + \E[V_i^2](\E[\bX_i\bX_i'])^{-1}.
\end{aligned}
\]</span> The first term is the asymptotic variance of the OLS estimator without measurement error. The presence of independent measurement error adds an additional positive definite component — increases the asymptotic variance (check this at least in the scalar case!).</p>
<p><br></p>
<p><em>Third subquestion</em>: we again proceed by wriring down the estimator and then substituting the causal and measurement models. We will do those substitutions step-by-step to keep things cleaner: <span id="eq-pset1-p5-meX-ex"><span class="math display">\[
\begin{aligned}
\hat{\bbeta} &amp;  = \left(\sum_{i=1}^N \bX_i^*\bX_i^{*'}  \right)^{-1}\sum_{i=1}^N \bX_i^*Y_i \\
&amp; = \left(\sum_{i=1}^N \bX_i^*\bX_i^{*'}  \right)^{-1}\sum_{i=1}^N \bX_i^* (\bX_i'\bbeta + U_i)\\
&amp; = \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i^*\bX_i^{*'}  \right)^{-1} \dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'\bbeta\\
&amp; \quad + \left(\dfrac{1}{N} \sum_{i=1}^N \bX_i^*\bX_i^{*'}  \right)^{-1} \dfrac{1}{N}\sum_{i=1}^N \bV_i\bX_i'\bbeta \\
&amp; \quad + \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i^*\bX_i^{*'}  \right)^{-1} \dfrac{1}{N} \sum_{i=1}^N \bX_iU_i\\
&amp; \quad + \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i^*\bX_i^{*'}  \right)^{-1}\dfrac{1}{N} \sum_{i=1}^N \bV_i U_i.
\end{aligned}
\tag{12}\]</span></span> We now analyze the different averages in the above expressions. By the law of large numbers it holds that <span class="math display">\[
\begin{aligned}
\dfrac{1}{N}\sum_{i=1}^N\bV_i\bX_i' &amp; \xrightarrow{p} \E[\bV_i\bX_i'] = \E[\bV_i]\E[\bX_i'] =0, \\
\dfrac{1}{N}\sum_{i=1}^N\bX_i U_i &amp; \xrightarrow{p} \E[\bX_iU_i]  =0, \\
\dfrac{1}{N}\sum_{i=1}^N \bV_i U_i &amp; \xrightarrow{p} \E[\bV_iU_i] = \E[\bV_i]\E[U_i] =0.
\end{aligned}
\]</span> It also holds that <span class="math display">\[
\begin{aligned}
\dfrac{1}{N} \sum_{i=1}^N \bX_i^*\bX_i^{*'} &amp; =   \dfrac{1}{N} \sum_{i=1}^N \bX_i\bX_i'   + \dfrac{1}{N} \sum_{i=1}^N \bV_i\bV_i'  \\
&amp; \quad +
\dfrac{1}{N} \sum_{i=1}^N \bX_i\bV_i' +
\dfrac{1}{N} \sum_{i=1}^N \bV_i\bX_i' \\
&amp; \xrightarrow{p} \E[\bX_i\bX_i'] + \E[\bV_i\bV_i']
\end{aligned}
\]</span> Combining the above convergence results, the continuous mapping theorem and <a href="#eq-pset1-p5-meX-ex" class="quarto-xref">Equation&nbsp;12</a> we get that <span class="math display">\[
\hat{\bbeta} \xrightarrow{p} \left(\E[\bX_i\bX_i']  + \E[\bV_i\bV_i'] \right)^{-1} \E[\bX_i\bX_i']\bbeta.
\]</span> We see that in general the OLS estimator is not consistent for <span class="math inline">\(\bbeta\)</span> if there is measurement error in the covariates.</p>
<p>Consistency holds if <span class="math inline">\(\E[\bV_i\bV_i']=0\)</span>. Since <span class="math inline">\(\E[\bV_i]=0\)</span>, it holds that <span class="math inline">\(\E[\bV_i\bV_i'] = \var(\bV_i)\)</span>. In other words, consistency requires that <span class="math inline">\(\var(\bV_i)=0\)</span>, which means there is no measurement error in <span class="math inline">\(\bX_i\)</span>.</p>
<p>To summarize, we find notable differences between the two kinds of measurement errors.</p>
<ul>
<li>Independent measurement error in the outcome variable does not break consistency or asymptotic normality. It only increases the asymptotic variances (reduces precision).</li>
<li>Independent measurement error in the covariates makes the OLS estimator inconsistent.</li>
</ul>
</details>
</section>
<section id="omitted-variable-bias-revisited" class="level3">
<h3 class="anchored" data-anchor-id="omitted-variable-bias-revisited">Omitted Variable Bias Revisited</h3>
<p>Let <span class="math inline">\(Y_i\)</span> be some outcome of interest. Let <span class="math inline">\(\bX_i\)</span> be an observed covariate vector; <span class="math inline">\(\E[\bX_i\bX_i']\)</span> is assumed to be invertible. Let <span class="math inline">\(U_i\)</span> be an unobserved component that satisfies <span class="math inline">\(\E[\bX_iU_i]=0\)</span>. Let <span class="math inline">\(\bW_i\)</span> be another group of variables that affect <span class="math inline">\(Y_i\)</span>. Suppose that <span class="math inline">\(Y_i\)</span> and <span class="math inline">\((\bX_i, \bW_i)\)</span> are related through the potential outcomes model <span class="math display">\[
Y_i^{(\bx, \bw)} = \bx'\bbeta + \bw'\bdelta + U_i.
\]</span></p>
<p>Suppose that <span class="math inline">\(\bW_i\)</span> is not observed, and we instead regress <span class="math inline">\(Y_i\)</span> only on <span class="math inline">\(\bX_i\)</span>. Find the probability limit of the corresponding OLS estimator. Make any necessary moment assumptions. When is that limit equal to <span class="math inline">\(\bbeta\)</span>?</p>
<details>
<summary>
Click to see the solution
</summary>
<p>Yet again the approach is to substitute the true model into the estimator. The observed outcomes satisfy <span class="math display">\[
Y_i = \bX_i'\bbeta + \bW_i'\bdelta + U_i.
\]</span></p>
<p>The OLS estimator of <span class="math inline">\(Y_i\)</span> on <span class="math inline">\(\bX_i\)</span> satisfies <span class="math display">\[
\begin{aligned}
\hat{\bbeta} &amp; = \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'   \right)^{-1}\dfrac{1}{N}\sum_{i=1}^N \bX_i Y_i\\
&amp; =  \bbeta+  \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'   \right)^{-1} \dfrac{1}{N} \sum_{i=1}^N \bX_i U_i \\
&amp; \quad + \left(\dfrac{1}{N}\sum_{i=1}^N \bX_i\bX_i'   \right)^{-1} \dfrac{1}{N} \sum_{i=1}^N \bX_i\bW_i'\bdelta
\end{aligned}
\]</span> We now handle the individual sums in the usual way. By the law of large numbers, continuous mapping theorem and our moment conditions it holds that <span class="math display">\[
\begin{aligned}
\dfrac{1}{N} \sum_{i=1}^N \bX_iU_i &amp; \xrightarrow{p} \E[\bX_iU_i] =0 ,\\
\dfrac{1}{N} \sum_{i=1}^N \bX_i\bW_i' &amp; \xrightarrow{p} \E[\bX_i\bW_i'] ,\\
\left( \dfrac{1}{N} \sum_{i=1}^N \bX_i\bX_i'\right)^{-1} &amp; \xrightarrow{p} \left( \E[\bX_i\bX_i'] \right)^{-1}.
\end{aligned}
\]</span> By the continuous mapping theorem we obtain the probability limit of <span class="math inline">\(\hat{\bbeta}\)</span>: <span class="math display">\[
\hat{\bbeta} \xrightarrow{p} \bbeta + \left(\E[\bX_i\bX'] \right)^{-1}\E[\bX_i\bW_i']\bdelta.
\]</span> This limit is equal to <span class="math inline">\(\bbeta\)</span> if <span class="math inline">\(\E[\bX_i\bW_i']\bdelta = 0\)</span>. Standard sufficient conditions are that <span class="math inline">\(\bdelta = 0\)</span> (and so <span class="math inline">\(\bW_i\)</span> are not important to <span class="math inline">\(Y_i\)</span>) or that <span class="math inline">\(\bX_i\)</span> and <span class="math inline">\(\bW_i\)</span> are orthogonal in the sense that <span class="math inline">\(\E[\bX_i\bW_i']=0\)</span>.</p>
</details>
</section>
</section>
<section id="applied-exercises" class="level2">
<h2 class="anchored" data-anchor-id="applied-exercises">Applied Exercises</h2>
<p>Applied exercises in this list of exercises serve as reminders on how to apply multivariate regression:</p>
<ul>
<li><span class="citation" data-cites="Wooldridge2020IntroductoryEconometricsModern">Wooldridge (<a href="#ref-Wooldridge2020IntroductoryEconometricsModern" role="doc-biblioref">2020</a>)</span> Exercise C9 in chapter 3 (see C7 in chapter 2 for some more context).</li>
<li><span class="citation" data-cites="James2023IntroductionStatisticalLearning">James et al. (<a href="#ref-James2023IntroductionStatisticalLearning" role="doc-biblioref">2023</a>)</span> Exercise 3.8 and 3.9.</li>
</ul>
<p>Check out chapter 3 in <span class="citation" data-cites="Heiss2024UsingPythonIntroductory">Heiss and Brunner (<a href="#ref-Heiss2024UsingPythonIntroductory" role="doc-biblioref">2024</a>)</span> and section 3.6 in <span class="citation" data-cites="James2023IntroductionStatisticalLearning">James et al. (<a href="#ref-James2023IntroductionStatisticalLearning" role="doc-biblioref">2023</a>)</span>.</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Heiss2024UsingPythonIntroductory" class="csl-entry" role="listitem">
Heiss, Florian, and Daniel Brunner. 2024. <em>Using <span>Python</span> for <span>Introductory Econometrics</span></em>. 2nd edition. New York: Independently Published.
</div>
<div id="ref-James2023IntroductionStatisticalLearning" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, and Jonathan E. Taylor. 2023. <em>An <span>Introduction</span> to <span>Statistical Learning</span>: <span>With Applications</span> in <span>Python</span></em>. Springer Texts in Statistics. Cham: Springer.
</div>
<div id="ref-Wooldridge2020IntroductoryEconometricsModern" class="csl-entry" role="listitem">
Wooldridge, Jeffrey M. 2020. <em>Introductory <span>Econometrics</span>: A <span>Modern Approach</span></em>. Seventh edition. Boston, MA: Cengage.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/vladislav-morozov\.github\.io\/econometrics-2\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/vladislav-morozov/econometrics-2/edit/main/src/exercises/exercises-linear-asymptotic.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/vladislav-morozov/econometrics-2/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>