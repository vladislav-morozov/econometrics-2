---
title: "Inference and the Delta Method"
subtitle: "Hypothesis Testing and Confidence Intervals"
author: Vladislav Morozov  
execution:
  eval: false
format:
  revealjs:
    width: 1150
    slide-number: true
    sc-sb-title: true
    incremental: true   
    logo: ../../themes/favicon.ico
    footer: "A Deeper Look at Linear Regression: Inference"
    footer-logo-link: "https://vladislav-morozov.github.io/econometrics-2/"
    theme: ../../themes/slides_theme.scss
    toc: TRUE
    toc-depth: 2
    toc-title: Contents
    transition: convex
    transition-speed: fast
slide-level: 4
title-slide-attributes:
    data-background-color: "#045D5D"
    data-footer: " "
filters:
  - reveal-header  
include-in-header: ../../themes/mathjax.html 
highlight-style: tango
---



## Introduction {background="#00100F"}
  
### Lecture Info {background="#43464B" visibility="uncounted"}


#### Learning Outcomes

This lecture is about  

<br>

By the end, you should be able to

- Do

#### References
 

::: {.nonincremental}

 

- 8-2 and E4+E4a in @Wooldridge2020IntroductoryEconometricsModern (careful with the specialized formulas in 8-2, they are more confusing than the general case in the lecture and those in E4)
- Or 7.11-7.13, 7.16, 7.18* in @Hansen2022Econometrics
- (*Curious background reading*): @Wooldridge2023WhatStandardError on what "standard error" might mean


::: 

 

### Reminder on the Empirical Example {background="#43464B" visibility="uncounted"}


#### Reminder: Empirical Model 

Studying link between wages and (education, experience)
$$
\begin{aligned}[]
& [\ln(\text{wage}_i)]^{\text{(education, experience)}} \\
&  =   \beta_1 + \beta_2 \times \text{education} \\
& \quad  + \beta_3 \times  \text{experience} + \beta_4 \times  \dfrac{\text{experience}^2}{100} + U_i
\end{aligned}
$$ {#eq-vector-inference-emp-model}

. . . 
 
Data: married white women from March 2009 CPS


```{python}
#| echo: true 
#| code-fold: true
#| code-summary: "Expand for full data preparation code"
import numpy as np
import pandas as pd
import statsmodels.api as sm

from statsmodels.regression.linear_model import OLS

# Read in the data
data_path = ("https://github.com/pegeorge/Econ521_Datasets/"
             "raw/refs/heads/main/cps09mar.csv")
cps_data = pd.read_csv(data_path)

# Generate variables
cps_data["experience"] = cps_data["age"] - cps_data["education"] - 6
cps_data["experience_sq_div"] = cps_data["experience"]**2/100
cps_data["wage"] = cps_data["earnings"]/(cps_data["week"]*cps_data["hours"] )
cps_data["log_wage"] = np.log(cps_data['wage'])

# Retain only married women white with present spouses
select_data = cps_data.loc[
    (cps_data["marital"] <= 2) & (cps_data["race"] == 1) & (cps_data["female"] == 1), :
]

# Construct X and y for regression 
exog = select_data.loc[:, ['education', 'experience', 'experience_sq_div']]
exog = sm.add_constant(exog)
endog = select_data.loc[:, "log_wage"]
```

::: footer

:::




#### Reminder: Estimation Results 

```{.python code-line-numbers="0-1"}
results = OLS(endog, exog).fit(cov_type='HC0') # Robust covariance matrix estimator
print(results.summary())
```

```{python} 
results = OLS(endog, exog).fit(cov_type='HC0')
print(results.summary())
```

#### Reminder: Parameters of Interest and Estimators

 
<br>

Our parameters of interest: 

1. $100\beta_2$. Estimate: $11.14$
2. $100\beta_3 + 20 \beta_4$. Estimate: $2.22$
3. $-50\beta_3/\beta_4$. Estimate: $36.67$


. . . 


<br>

<div class="rounded-box">

What is the interpretation of those parameters?

</div>



#### Reminder: Empirical Questions


<br> 

1. Does education matter at all? (up to our statistical confidence)
2. Does experience matter at all? (up to our statistical confidence)
3. Is the best amount of experience to have equal to 25 years? (up to our statistical confidence)
4. How certain are we of our estimates of target parameters?


## Background and Definitions for Testing {background="#00100F"}
   

#### Basic Setup: Hypotheses

Suppose that we have a model with some parameters $\theta$ (of whatever nature):

Two competing *hypotheses* (statements about parameters $\theta$)
$$
H_0: \theta\in \Theta_0 \text{  vs.  } H_1: \theta \in \Theta_1 
$$
for some nonintersecting $\Theta_0$ and $\Theta_1$

. . .

Example

- $H_0: \beta_2=0$ (education does not affect wages)
- $H_1: \beta_2\neq 0$ (education affects wages)
 

#### Definition of a Test

Informally, a test is a *decision rule*: you see the sample and then you decide in favor of $H_0$ or $H_1$


. . . 

<br>

Formally:

<div class="rounded-box">

::: {#def-vector-inference-test}

A test $T$ is a function of the sample $(X_1, \dots, X_N)$ to the space $\curl{\text{Reject} H_0,  \text{Do not reject }H_0}$

:::

</div>




#### Power

<br>

<div class="rounded-box">

::: {#def-vector-inference-power}

The power function $\text{Power}_T(\theta)$ of the test $T$ is the probability that $T$ rejects if $\theta$ is the true parameter value:
$$
\text{Power}_T(\theta) = P(T(X_1, \dots, X_N)=\text{Reject }H_0|\theta)
$$

:::

</div>

 

#### Test Size

Maximal power under the null has a special name 
<div class="rounded-box">

::: {#def-vector-inference-size}

The test size $\alpha$ of the test $T$ is 
$$
\alpha = \max_{\theta\in\Theta_0} \text{Power}_T(\theta)
$$

:::

</div>

In other words, the probability of falsely rejecting the null (type I error)


#### What Defines a Good Test? 

The best possible test has perfect detection:

- Never rejects under $H_0$
- Always reject under $H_1$

. . . 

<br>

Usually impossible in practice. Instead we ask

- Not too much false rejection under $H_0$ (e.g. $\leq 5\%$ of the time)
- As much rejection as possible under $H_1$ 

#### Test Consistency

- For given sample sizes, usually cannot power function
- Substitute requirement that asymptoticall you detect any failure of $H_0$:
 
. . .

<div class="rounded-box">

::: {#def-vector-inference-consistency}

$T$ is *consistent* if for any $\theta\in \Theta_1$ 
$$ \small
 \lim_{N\to\infty} P(T(X_1, \dots, X_N)=\text{Reject }H_0|\theta) = 1
$$

:::

</div>

::: {.callout-important appearance="minimal"}

As with estimators, we say "test" when we mean a sequence of tests, one for each sample size.

:::

::: footer

:::


#### Asymptotic Size

- Also, can't necessarily control rejection under $H_0$ in finite
- But can require it asymptotically


<div class="rounded-box">

::: {#def-vector-inference-asy-significane}

The asymptotic size $\alpha$ of the test $T$ is 
$$
\alpha = \lim_{N\to\infty} \max_{\theta\in\Theta_0}  P(T(X_1, \dots, X_N)=\text{Reject }H_0|\theta) 
$$

:::

</div>


## Linear Hypotheses {background="#00100F"}

### A Single Linear Hypothesis {background="#43464B" visibility="uncounted"}

#### Single Example Hypothesis

Let's start with our first empirical question:

<div class="rounded-box">

Does education affect wages?

</div>

. . .

<br>

In the framework of @eq-vector-inference-emp-model can translate to 
$$
H_0: \beta_2 = 0, \quad H_1: \beta_2\neq 0
$$

. . .

Here $\Theta_1 = \curl{0}$ and $\Theta_2 = \R - \curl{0}$



#### How Testing Works in General

*How do we construct a test/decision rule?*

<br>

. . .

The basic approach to testing is surprisingly simple

1. Pick a "statistic" (=some known function of the data) that behaves "differently" under $H_0$ and $H_1$
2. Is the observed value of the statistic compatible with $H_0$? If not, reject $H_0$ in favor or $H_1$. If yes, do not reject $H_0$


#### Picking a Statistic

- In principle, can pick any statistic. Some are more "standard"
- For testing hypotheses about coefficients, there are three main classes
  - Wald statistics: need only *unrestricted* estimates 
  - Lagrange multiplier (LM): need *restricted* estimates 
  - Likelihood ratio (LR): need both

. . .
 

::: {.callout-note appearance="minimal"}

Wald tests easiest to work with in linear models, but others have their uses in different contexts 
:::


#### Convergence of $\hat{\beta}_2$

Recall asymptotic distribution result for OLS estimator
$$\small
\sqrt{N}\left( \hat{\bbeta}- \bbeta \right) \xrightarrow{d} N(0, \avar(\hat{\bbeta}))
$$

. . . 

It implies (why?) that
$$ \small
\dfrac{\hat{\beta}_2 - \beta_2}{\sqrt{ \avar(\hat{\beta}_2)/N }  } \xrightarrow{d} N\left(0, 1\right)
$$
where $\avar(\hat{\beta}_2)$ is the (2, 2) element of $\avar(\hat{\bbeta})$


#### $t$-statistic

Suppose that we have a consistent estimator of $\avar(\hat{\bbeta})$:
$$ \small
\widehat{\avar}(\hat{\bbeta}) \xrightarrow{p} \avar(\hat{\bbeta})
$$

. . .

Then if $H_0: \beta_2 = 0$, by Slutsky's theorem (why?) it holds that
$$ \small
t = \dfrac{\hat{\beta}_2}{\sqrt{ \widehat{\avar}(\hat{\beta}_2)/N }  } \xrightarrow{d} N\left(0, 1\right)
$$
$t$ is called a $t$-statistic; $\sqrt{ \widehat{\avar}(\hat{\beta}_2)/N }$ — standard error of $\hat{\beta}_2$

::: footer

:::

#### Decision Rule: Test  {#sec-ols-inference-t-test}

We call the following the "asymptotic level $\alpha$ $t$-test":


<br>

<div class="rounded-box">

Let $z_{1-\alpha/2} = \Phi^{-1}(1-\alpha/2)$. Then

- Reject $H_0$ is $\abs{t}>z_{1-\alpha/2}$
- Do not reject $H_0$ is $\abs{t}\leq z_{1-\alpha/2}$


</div>

#### Illustration: Extracting Standard Errors {.scrollable}

Can get $\widehat{\avar}(\hat{\bbeta})$ from the `results` object:
```{python}
#| echo: true
(results.nobs)*results.cov_params()
```
`cov_params()` extracts *standard errors*

::: footer

:::

#### Illustration: Doing the Test by Hand

Compute $t$-statistic as
```{python}
#| echo: true
t = (results.params.iloc[1])/np.sqrt(results.cov_params().iloc[1, 1])
print(t)
```

- Can compare `t` statistic to suitable quantile of the normal
- Set $\alpha=0.05$ if want to reject at most 5% under $H_0$ in the limit

. . .

```{python}
#| echo: true
from scipy.stats import norm
np.abs(t) > norm.ppf(1-0.05/2)
```
Reject $H_0$ in favor $H_1: \beta_2\neq 0$ at 5\% asymptotic level 

::: footer

:::

#### Illustration: Using `t_test()`

Can also use 
```{python}
#| echo: true
results.t_test(np.array([0, 1, 0, 0]), use_t=False)
```

. . .

- Decision by comparing with the $p$-value
- Can reject with high confidence (very small $p$-value)

#### $t$-Statistic under $H_0$

What is the (asymptotic) probability of rejecting under $H_0$?

$$
\begin{aligned}
& P\left(\text{Reject} H_0|H_0 \right) = P\left(\abs{t}>z_{1-\alpha/2} |H_0\right) \\
& = P\left( \abs{ \dfrac{\hat{\beta}_2}{\sqrt{ \widehat{\avar}(\hat{\beta}_2)/N }  }}> z_{1-\alpha/2}|H_0 \right)\\
& \to 2(1- Phi(z_{1-\alpha/2})) = \alpha 
\end{aligned}
$$

. . .

The test has asymptotic size $\alpha$

#### $t$-Statistic under $H_1$


What happens to $t$ under $H_1$? Suppose that $\beta_2\neq 0$ is the true value. Can write
$$ \small 
t = \dfrac{\hat{\beta}_2}{\sqrt{ \widehat{\avar}(\hat{\beta}_2)/N }  }=  \underbrace{\dfrac{\hat{\beta}_2 - \beta_2}{\sqrt{ \widehat{\avar}(\hat{\beta}_2)/N }  }}_{\scriptsize \xrightarrow{d} N(0, 1)} +  \underbrace{\dfrac{\beta_2}{\sqrt{ \widehat{\avar}(\hat{\beta}_2)/N }  }}_{\scriptsize \xrightarrow{p} \pm \infty }
$$


. . .

It follows (why?) that the $t$-test is consistent
$$ \small
P(\text{Reject } H_0|H_1) \xrightarrow{N\to\infty} 1
$$ 



#### $t$-Test for $H_0:\beta_2 = c$

More generally, can test
$$
H_0: \beta_k = c \text{ vs } H_1: \beta_k \neq c
$$

. . . 

$t$-statistic
$$
t = \dfrac{\hat{\beta}_2 - c}{\sqrt{ \widehat{\avar}(\hat{\beta}_k)/N }  }
$$ {#eq-vector-inference-t-general}

Same decision rule: compare $t$ to $z_{1-\alpha/2}$

#### Intuition: What the Test Does

- Under $H_0$, the $t$ statistic should be "well-behaved": normal and centered at 0. Big values of $t$-statistic unlikely
- So if we see a big $t$-statistic, such a value is unlikely under $H_0$ — evidence against $H_0$
- If value is large enough, we think the evidence is strong enough to be reasonably incompatible with $H_0$ — rejection


#### Combined Result: $t$-statistics


<div class="rounded-box">

::: {#prp-vector-inference-t}

Let the assumptions for asymptotic normality of the OLS estimator hold. Let $t$ be defined as in @eq-vector-inference-t-general. Then

1. If $H_0: \beta_k=c$ holds, then $t\xrightarrow{d} N(0, 1)$ and the associated test has asymptotic size $\alpha$
2. If $H_0: \beta_k=c$ does not hold, then $t\xrightarrow{p}\pm\infty$ and the associated test is consistent



:::

</div>


#### Estimating $\avar(\hat{\bbeta})$

One remaining issue: how to estimate 
$$
\avar(\hat{\bbeta}) =  \left( \E[\bX_i\bX_i']\right)^{-1} \E[U_i^2\bX_i\bX_i']\left( \E[\bX_i\bX_i']\right)^{-1} 
$$

. . . 


Can estimate using "sample analogs"

1. $\left( \E[\bX_i\bX_i']\right)^{-1}$ with $\left( N^{-1}\sum_{i=1}^N \sum_{i=1}^N \bX_i\bX_i'\right)^{-1}$
2. $\E[U_i^2\bX_i\bX_i']$ with $N^{-1}\sum_{i=1}^N \hat{U}_i \bX_i\bX_i'$ for $\hat{U}_i = Y_i-\bX_i'\hat{\bbeta}$


#### Estimating $\avar(\hat{\bbeta})$: Robust Standard Errors

Resulting $\widehat{\avar}(\hat{\bbeta})$ is consistent:
$$
\widehat{\avar}(\hat{\bbeta}) \xrightarrow{p} {\avar}(\hat{\bbeta})
$$

- Can use in test statistics
- $N^{-1}\widehat{\avar}(\hat{\bbeta})$ is called  *robust* (or *heteroskedasticity robust*) standard errors (specifically, HC0). 
- In `statsmodels`, we used them by called `OLS(endog, exog).fit(cov_type='HC0')`








### Multiple Linear Hypothesis {background="#43464B" visibility="uncounted"}

#### Potentially Multiple

#### 
 

Special case

Wald statistics is the square of the $t$-statistic

- You lose nothing by doing a Wald test even if you have a single hypothesis
 


## Nonlinear Hypotheses and the Delta Method  {background="#00100F"}

### The Delta Method {background="#43464B" visibility="uncounted"}

####

### Nonlinear Wald Tests  {background="#43464B" visibility="uncounted"}

#### 

A

## Confidence Intervals and Sets {background="#00100F"}

####

## Recap and Conclusions {background="#00100F"}
  
#### Recap

In this lecture we

1. Did
   
#### Next Questions

<br>

How 

#### References {.allowframebreaks visibility="uncounted"}

::: {#refs}
:::